{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "d7dbea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "8caae505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    x,y,z = x\n",
    "    return (x - z)**2 + (2*y + z)**2 + (4*x - 2*y + z)**2 + x + y\n",
    "\n",
    "def grad_f1(x):\n",
    "    x,y,z = x[0], x[1], x[2]\n",
    "    dx = 2*(x - z) + 8*(4*x - 2*y + z) + 1\n",
    "    dy = 4*(2*y + z) - 4*(4*x - 2*y + z) + 1\n",
    "    dz = -2*(x - z) + 2*(2*y + z) + 2*(4*x - 2*y + z)\n",
    "    \n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def hess_f1(x):\n",
    "    dxx = 34 # 2 + 32\n",
    "    dxy = -16\n",
    "    dxz = 6 #-2 + 8\n",
    "    dyy = 16\n",
    "    dyz = 0\n",
    "    dzz = 6\n",
    "    \n",
    "    return np.array([[dxx, dxy, dxz], [dxy, dyy, dyz], [dxz, dyz, dzz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "08eaaa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0),\n",
       " array([1, 1, 0]),\n",
       " array([[ 34, -16,   6],\n",
       "        [-16,  16,   0],\n",
       "        [  6,   0,   6]]))"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_x1 = np.array([0,0,0]) \n",
    "f1(f1_x1), grad_f1(f1_x1), hess_f1(f1_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "c45d29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    x,y,z = x\n",
    "    return (x - 1)**2 + (y - 1)**2 + 100*(y-x**2)**2 + 100*(z-y**2)**2\n",
    "\n",
    "def grad_f2(x):\n",
    "    x,y,z = x[0], x[1], x[2]\n",
    "    dx = 2*x - 2 - 400 * x * y + 400 * x**3\n",
    "    dy = 2*y - 2 + 200 * (y - x**2) - 400*z*y + 400 * y**3\n",
    "    dz = 200 * (z - y**2)\n",
    "        \n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def hess_f2(x):\n",
    "    x,y,z = x[0], x[1], x[2]\n",
    "    \n",
    "    dxx = 2 - 400 * y + 1200 * x**2\n",
    "    dxy = -400 * x\n",
    "    dxz = 0\n",
    "    dyy = 2 + 200 - 400 * z + 1200 * y**2\n",
    "    dyz = -400 * y\n",
    "    dzz = 200\n",
    "    return np.array([[dxx, dxy, dxz], [dxy, dyy, dyz], [dxz, dyz, dzz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "6fff7db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(11.6),\n",
       " array([115.6,  67.6, -48. ]),\n",
       " array([[1250., -480.,    0.],\n",
       "        [-480., 1450., -480.],\n",
       "        [   0., -480.,  200.]]))"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2_x1 = np.array([1.2, 1.2, 1.2])\n",
    "f2(f2_x1), grad_f2(f2_x1), hess_f2(f2_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "b2ac8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    x,y = x\n",
    "    return (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "\n",
    "def grad_f3(x):\n",
    "    x,y = x[0], x[1]\n",
    "    \n",
    "    dx = -12.75 * 6*x + 3*y - 4*x*y - 2*x*y**2 + 4.5*y**2 + 2*x*y**4 - 4*x*y**3 + 5.25 * y**3 + 2*x*y**6\n",
    "    dy = 3*x + 9*y*x - 4*x**2*y - 2*x**2 + 15.75*y**2 *x + 2*x**2 * y - 6 * x**2 * y**2 + 4*x**3*y**3 + 6*x**2*y**5\n",
    "    \n",
    "    return np.array([dx, dy])\n",
    "\n",
    "def hess_f3(x):\n",
    "    x,y = x[0], x[1]\n",
    "    \n",
    "    dxx = 6 - 4*y - 2*y**2 + 2*y**4 - 4*y**3 + 2*y**6\n",
    "    dxy = 3 - 4*x - 4*x*y + 9*y + 8*x*y**3 - 12*x*y**2 + 15.75*y**2 + 12*x*y**5\n",
    "    dyy = 9*x - 4*x**2 + 31.5*y*x + 2*x**2 - 12*x**2*y + 12*x**2*y**2 + 30*x**2*y**4\n",
    "    return np.array([[dxx, dxy], [dxy, dyy]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "b6582d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(14.203125),\n",
       " array([-69.75,  27.75]),\n",
       " array([[ 0.  , 27.75],\n",
       "        [27.75, 68.5 ]]))"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3_x1 = np.array([1,1])\n",
    "f3(f3_x1), grad_f3(f3_x1), hess_f3(f3_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "bdd8fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 1e-5 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "8f3a8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(x, grad_f, lr_fn, n_steps, t=None):\n",
    "    \n",
    "    if t is not None:\n",
    "        i = 0\n",
    "        start = time.perf_counter()\n",
    "        while time.perf_counter() - start < t:\n",
    "            x = x - lr_fn(i) * grad_f(x)\n",
    "            i += 1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            x = x - lr_fn(i) * grad_f(x)\n",
    "        \n",
    "    return x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "06be5673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def polyak(x: np.ndarray, grad_f, lr_fn, mu, n_steps, t=None):\n",
    "    x_prev = x\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            dx = grad_f(x)\n",
    "            x_new = x - lr_fn(i) * dx  + mu * (x - x_prev)\n",
    "        \n",
    "            x_prev = np.copy(x)\n",
    "            x = x_new\n",
    "            i+=1\n",
    "        print(i)\n",
    "        return x\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            dx = grad_f(x)\n",
    "            x_new = x - lr_fn(i) * dx  + mu * (x - x_prev)\n",
    "        \n",
    "            x_prev = x\n",
    "            x = x_new\n",
    "            i+=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "42bb25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(x, f, grad_f, lr_fn, mu, n_steps, t=None):\n",
    "    x_prev = np.copy(x)\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            x_ahead = x + mu * (x - x_prev)\n",
    "            dx = grad_f(x_ahead)\n",
    "            x_new = x - lr_fn(i) * dx + mu * (x - x_prev)\n",
    "    \n",
    "            x_prev = x\n",
    "            x = x_new\n",
    "            i+=1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            x_ahead = x + mu * (x - x_prev)\n",
    "            dx = grad_f(x_ahead)\n",
    "            x_new = x - lr_fn(i) * dx + mu * (x - x_prev)\n",
    "    \n",
    "            x_prev = x\n",
    "            x = x_new\n",
    "            i+=1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "044fa1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adagrad(x, grad_f, lr_fn, n_steps, eps=1e-8, t=None):\n",
    "    x = np.array(x, dtype=float)\n",
    "    n = len(x)\n",
    "    lr = .4\n",
    "    \n",
    "    grad_sq_sum = np.zeros(n)\n",
    "    \n",
    "     \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            grad = np.array(grad_f(x))\n",
    "        \n",
    "            # Accumulate squared gradients\n",
    "            grad_sq_sum += grad ** 2\n",
    "            \n",
    "            # Compute D_k^{-1/2}\n",
    "            D_inv_sqrt = np.diag(1.0 / (np.sqrt(grad_sq_sum) + eps))\n",
    "            # Adaptive step\n",
    "            step = lr * D_inv_sqrt @ grad\n",
    "            x_new = x - step\n",
    "            \n",
    "            x = x_new\n",
    "            i+= 1\n",
    "        print(i)\n",
    "        return x\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            grad = np.array(grad_f(x))\n",
    "            \n",
    "            # Accumulate squared gradients\n",
    "            grad_sq_sum += grad ** 2\n",
    "            \n",
    "            # Compute D_k^{-1/2}\n",
    "            D_inv_sqrt = np.diag(1.0 / (np.sqrt(grad_sq_sum) + eps))\n",
    "            \n",
    "            # Adaptive step\n",
    "            step = lr * D_inv_sqrt @ grad\n",
    "            x_new = x - step\n",
    "            \n",
    "            x = x_new\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "93b767ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.19791666666565474)"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(adagrad(f1_x1, grad_f1, learning_rate, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94603437",
   "metadata": {},
   "source": [
    "Newton and BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "e15c33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_positive_definite(H):\n",
    "    try:\n",
    "        np.linalg.cholesky(H)\n",
    "        return True\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "bb4858f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(x0, grad_f, hess_f, n_steps=100, t=None, lr=None):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            grad = np.array(grad_f(x))\n",
    "            hess = np.array(hess_f(x))\n",
    "            \n",
    "            hess_inv = np.linalg.inv(hess)\n",
    "            \n",
    "            lr = lr if lr is not None else learning_rate(i)\n",
    "            # Compute Newton step\n",
    "            x = x - learning_rate(i) * hess_inv @ grad\n",
    "            i += 1\n",
    "\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            grad = np.array(grad_f(x))\n",
    "\n",
    "            hess = np.array(hess_f(x)) + 1e-4 * np.eye(len(x))\n",
    "            \n",
    "            hess_inv = np.linalg.inv(hess)\n",
    "            \n",
    "            # Compute Newton step\n",
    "            x = x - hess_inv @ grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "e96eed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum3(f2), print(\"Newton: \", f2(newton(np.array([0,0,0]), grad_f1, hess_f1, 100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "e9266eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x, grad_f, lr_fn, n_steps=100, t=None):\n",
    "    x = np.array(x, dtype=float)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        grad = grad_f(x) \n",
    "        x = x - lr_fn(i) * grad\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb9f53",
   "metadata": {},
   "source": [
    "### BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "d97b3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs(x, grad_f, lr_fn, n_steps, t=None):\n",
    "    B = np.eye(len(x)) * 0.0001\n",
    "    grad = grad_f(x)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        x_new = x - B @ grad\n",
    "        grad_new = grad_f(x_new)\n",
    "\n",
    "        delta = (x_new - x).reshape((-1, 1))\n",
    "        gamma = (grad_new - grad).reshape((-1, 1))\n",
    "        rho = 1.0 / (delta.T @ gamma + 1e-10)\n",
    "\n",
    "        if np.isfinite(rho) and rho > 0:\n",
    "            I = np.eye(len(x))\n",
    "            B = (I - rho * delta @ gamma.T) @ B @ (I - rho * gamma @ delta.T) + rho * delta @ delta.T\n",
    "\n",
    "        x, grad = x_new, grad_new\n",
    "        # print(f\"x: {x.flatten()}, grad norm: {np.linalg.norm(grad)}\")\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "fcabe647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfgs(np.array([1,0,0]), grad_f1, hess_f1, 100), minimum3(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "ee979b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f3(bfgs(np.array([1,0]), grad_f3, hess_f3, 100)), minimum2(f3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "f75232aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfgs(np.array([1,0,0]), grad_f2, hess_f2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "888c851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def l_bfgs(x, grad_f, m=10, n_steps=100):\n",
    "    grad = grad_f(x).reshape(-1, 1)\n",
    "\n",
    "    B = []      \n",
    "    gamma = []  \n",
    "    rho = []  \n",
    "\n",
    "    for step in range(n_steps):\n",
    "        q = grad.copy()\n",
    "        alpha = []\n",
    "\n",
    "        for i in reversed(range(len(B))):\n",
    "            s_i, y_i, rho_i = B[i], gamma[i], rho[i]\n",
    "            alpha_i = rho_i * (s_i.T @ q).item()\n",
    "            alpha.append(alpha_i)\n",
    "            q = q - alpha_i * y_i\n",
    "\n",
    "        if B:\n",
    "            s_last, y_last = B[-1], gamma[-1]\n",
    "            H0 = (s_last.T @ y_last).item() / (y_last.T @ y_last).item()\n",
    "            r = H0 * q\n",
    "        else:\n",
    "            r = q\n",
    "\n",
    "        for i in range(len(B)):\n",
    "            s_i, y_i, rho_i = B[i], gamma[i], rho[i]\n",
    "            beta_i = rho_i * (y_i.T @ r).item()\n",
    "            r = r + s_i * (alpha[-(i + 1)] - beta_i)\n",
    "\n",
    "        x_new = x - r.flatten()\n",
    "        grad_new = grad_f(x_new).reshape(-1, 1)\n",
    "\n",
    "        s_k = (x_new - x).reshape(-1, 1)\n",
    "        y_k = (grad_new - grad).reshape(-1, 1)\n",
    "        ys = (y_k.T @ s_k).item()\n",
    "\n",
    "        if ys > 1e-10:  # safeguard\n",
    "            rho_k = 1.0 / ys\n",
    "            if len(B) == m:\n",
    "                B.pop(0)\n",
    "                gamma.pop(0)\n",
    "                rho.pop(0)\n",
    "            B.append(s_k)\n",
    "            gamma.append(y_k)\n",
    "            rho.append(rho_k)\n",
    "\n",
    "        x, grad = x_new, grad_new\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "c1928654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.546678239835239e-31)"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2(bfgs(np.array([0,0,0]), grad_f2, hess_f2, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "4aa5a7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7949332 , 0.63239939, 0.4028514 ])"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_bfgs(np.array([0,0,0]), grad_f2, hess_f2, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "18e99798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2(np.array([1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "6e1becf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum3(f2), print(\"BFGS: \", bfgs(np.array([0,0,0]), grad_f2, hess_f2, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063c60a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "2eb0fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum2(f):\n",
    "    \"\"\"Finds approximate minimum of f(x)\"\"\"\n",
    "    xs = np.linspace(-3, 3, 1000)\n",
    "    ys = np.linspace(-3, 3, 1000)\n",
    "    X, Y = np.meshgrid(xs, ys)  \n",
    "    Z = f(np.array([X, Y]))  \n",
    "    \n",
    "    min_idx = np.unravel_index(np.argmin(Z), Z.shape)  \n",
    "    bx, by, bz = X[min_idx], Y[min_idx], Z[min_idx]\n",
    "    return np.array([bx, by, bz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "bf59e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum3(f):\n",
    "    \"\"\"Finds approximate minimum of f(x)\"\"\"\n",
    "    xs = np.linspace(-3, 3, 100)\n",
    "    ys = np.linspace(-3, 3, 100)\n",
    "    zs = np.linspace(-3, 3, 100)\n",
    "    \n",
    "    X, Y, Z = np.meshgrid(xs, ys, zs)  \n",
    "    W = f(np.array([X, Y, Z]))  \n",
    "    \n",
    "    min_idx = np.unravel_index(np.argmin(W), W.shape)  \n",
    "    bx, by, bz, bw = X[min_idx], Y[min_idx], Z[min_idx], W[min_idx]\n",
    "    return np.array([bx, by, bz, bw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "8be12379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 minimum: [-0.15151515 -0.21212121  0.15151515 -0.19651056]\n",
      "f2 minimum: [1. 1. 1. 0.]\n",
      "f3 minimum: [3.00000000e+00 5.01501502e-01 5.21242614e-05]\n"
     ]
    }
   ],
   "source": [
    "f1_xopt = minimum3(f1)\n",
    "f2_xopt = minimum3(f2)\n",
    "f3_xopt = minimum2(f3)\n",
    "print(\"f1 minimum:\", f1_xopt)\n",
    "print(\"f2 minimum:\", f2_xopt)\n",
    "print(\"f3 minimum:\", f3_xopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "0293c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum(f):\n",
    "    if f == f1 or f == f2:\n",
    "        return minimum3(f)\n",
    "    return minimum2(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "cac05bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_steps(f, grad_f, hess_f, x0, steps):\n",
    "    print(\"True minimum\", minimum(f)[-1], \"at \", minimum(f)[:-1])\n",
    "    for step in steps:\n",
    "        print(\"Steps, \", step)\n",
    "        print(\"GD: \", f(gd(x0, grad_f, learning_rate, step)))\n",
    "        print(\"Polyak: \", f(polyak(x0, grad_f, learning_rate, 0.1, step)))\n",
    "        print(\"Nesterov: \", f(nesterov(x0, f, grad_f, learning_rate, 0.1, step)))\n",
    "        print(\"Adagrad: \", f(adagrad(x0, grad_f, learning_rate, step)))\n",
    "        # print(\"Newton: \", f(newton(x0, grad_f, hess_f, step)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "351bb947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 1e-5 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "f9009436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 5.2124261432689534e-05 at  [3.        0.5015015]\n",
      "Steps,  2\n",
      "GD:  766.5966317471315\n",
      "Polyak:  317.3669399261159\n",
      "Nesterov:  337.8935150873536\n",
      "Adagrad:  58009.331518370884\n",
      "\n",
      "Steps,  5\n",
      "GD:  573.3181260243873\n",
      "Polyak:  234.18423832681148\n",
      "Nesterov:  251.2675637282102\n",
      "Adagrad:  30478.918874218594\n",
      "\n",
      "Steps,  10\n",
      "GD:  391.01982633597123\n",
      "Polyak:  180.14097490210202\n",
      "Nesterov:  191.6422296038764\n",
      "Adagrad:  16621.878755146845\n",
      "\n",
      "Steps,  100\n",
      "GD:  41.4483127130285\n",
      "Polyak:  27.34367484514155\n",
      "Nesterov:  28.13095223694685\n",
      "Adagrad:  1315.5377354409761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1x0 = np.array([0, 0, 0])\n",
    "f1x1 = np.array([1, 1, 0])\n",
    "f2x0 = np.array([1.2, 1.2, 1.2])\n",
    "f2x1 = np.array([-1, 1.2, 1.2])\n",
    "f3x0 = np.array([1,1])\n",
    "f3x1 = np.array([4.5, 4.5])\n",
    "\n",
    "steps = [2, 5, 10, 100]\n",
    "f = f3\n",
    "grad_f = grad_f3\n",
    "hess_f = hess_f3\n",
    "\n",
    "test_steps(f, grad_f, hess_f, f3x1, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "9e10ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_steps(f, grad_f, hess_f, f1x1, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "f765bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 0.001 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "b8c15a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2 1.2 1.2]\n",
      "True minimum 0.0 at  [1. 1. 1.]\n",
      "Steps,  2\n",
      "GD:  0.04360204395724923\n",
      "Polyak:  0.029878998002554\n",
      "Nesterov:  0.02673542046251252\n",
      "Adagrad:  11.212136336931973\n",
      "Newton:  6.486502125611452\n",
      "\n",
      "Steps,  5\n",
      "GD:  0.018222098858116126\n",
      "Polyak:  0.018111957810387373\n",
      "Nesterov:  0.01825287933581621\n",
      "Adagrad:  10.884354328434366\n",
      "Newton:  7.82723804484026\n",
      "\n",
      "Steps,  10\n",
      "GD:  0.018114796902295175\n",
      "Polyak:  0.018026193463732743\n",
      "Nesterov:  0.018042756516489775\n",
      "Adagrad:  10.524769246910026\n",
      "Newton:  32.57752757205745\n",
      "\n",
      "Steps,  100\n",
      "GD:  0.017367128919067866\n",
      "Polyak:  0.017199958422235238\n",
      "Nesterov:  0.01721471000097329\n",
      "Adagrad:  8.795304386701261\n",
      "Newton:  3523.7010595623265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = f2\n",
    "grad_f = grad_f2\n",
    "hess_f = hess_f2\n",
    "\n",
    "print(f2x0)\n",
    "test_steps(f, grad_f, hess_f, f2x0, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "5f03af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 0.0 at  [1. 1. 1.]\n",
      "Steps,  2\n",
      "GD:  5.229583521614642\n",
      "Polyak:  4.478010157939434\n",
      "Nesterov:  5.73751903199277\n",
      "Adagrad:  13.332066264049159\n",
      "Newton:  13.335799674114092\n",
      "\n",
      "Steps,  5\n",
      "GD:  4.227341057837024\n",
      "Polyak:  4.206751434677671\n",
      "Nesterov:  4.320012289083483\n",
      "Adagrad:  12.938862640765567\n",
      "Newton:  20.325429321856642\n",
      "\n",
      "Steps,  10\n",
      "GD:  4.20332860424492\n",
      "Polyak:  4.202417733869578\n",
      "Nesterov:  4.200249207030582\n",
      "Adagrad:  12.50992146936056\n",
      "Newton:  47.99574664249103\n",
      "\n",
      "Steps,  100\n",
      "GD:  4.162038855665383\n",
      "Polyak:  4.156500293012095\n",
      "Nesterov:  4.153848805697812\n",
      "Adagrad:  10.487659531267003\n",
      "Newton:  3589.711514754642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_steps(f, grad_f, hess_f, f2x1, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "81bf0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 0.00002 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "2e04b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 5.2124261432689534e-05 at  [3.        0.5015015]\n",
      "Steps,  2\n",
      "GD:  14.172429833366285\n",
      "Polyak:  14.170885263029238\n",
      "Nesterov:  14.170884914992083\n",
      "Adagrad:  14.20218149283947\n",
      "Newton:  14.196702713495865\n",
      "\n",
      "Steps,  5\n",
      "GD:  14.127347739705236\n",
      "Polyak:  14.120737629445859\n",
      "Nesterov:  14.120735973611062\n",
      "Adagrad:  14.201359799053826\n",
      "Newton:  14.24856149388566\n",
      "\n",
      "Steps,  10\n",
      "GD:  14.054718428955553\n",
      "Polyak:  14.03986085307536\n",
      "Nesterov:  14.039856892179442\n",
      "Adagrad:  14.200432977586338\n",
      "Newton:  14.203125211194463\n",
      "\n",
      "Steps,  100\n",
      "GD:  13.175395207257178\n",
      "Polyak:  13.055663113603089\n",
      "Nesterov:  13.055622129439703\n",
      "Adagrad:  14.19557041905663\n",
      "Newton:  14.203125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = f3\n",
    "grad_f = grad_f3\n",
    "hess_f = hess_f3\n",
    "\n",
    "test_steps(f, grad_f, hess_f, f3x0, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "fa674423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 5.2124261432689534e-05 at  [3.        0.5015015]\n",
      "Steps,  2\n",
      "GD:  12.43281596089588\n",
      "Polyak:  48.929151079532424\n",
      "Nesterov:  48.26973667113842\n",
      "Adagrad:  174802.90334024787\n",
      "Newton:  174787.39590967732\n",
      "\n",
      "Steps,  5\n",
      "GD:  12.513887697772656\n",
      "Polyak:  55.536960158281005\n",
      "Nesterov:  54.584161483235654\n",
      "Adagrad:  174793.794192175\n",
      "Newton:  174748.44359514368\n",
      "\n",
      "Steps,  10\n",
      "GD:  12.646195813283086\n",
      "Polyak:  51.47237658916009\n",
      "Nesterov:  50.672956432744265\n",
      "Adagrad:  174783.51999161392\n",
      "Newton:  174683.519713985\n",
      "\n",
      "Steps,  100\n",
      "GD:  14.418963181952417\n",
      "Polyak:  30.205778485525904\n",
      "Nesterov:  30.018365665044307\n",
      "Adagrad:  174729.62288745432\n",
      "Newton:  173514.16284713175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_steps(f, grad_f, hess_f, f3x1, steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "6b4c5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time(f, grad_f, hess_f, x0, step, times):\n",
    "    print(\"True minimum\", f2_xopt[-1])\n",
    "    for _time in times:\n",
    "        print(\"Time, \", _time)\n",
    "        print(\"GD: \", f(gd(x0, grad_f, learning_rate, step, t=_time)))\n",
    "        print(\"Polyak: \", f(polyak(x0, grad_f, learning_rate, 0.1, step, t=_time)))\n",
    "        print(\"Nesterov: \", f(nesterov(x0, f, grad_f, learning_rate, 0.1, step, t=_time)))\n",
    "        print(\"Adagrad: \", f(adagrad(x0, grad_f, learning_rate, 0.1, step, t=_time)))\n",
    "        print(\"Newton: \", f(newton(x0, grad_f, hess_f, step, t=_time)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "6f651e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 1e-7 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "b7546db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 0.0\n",
      "Time,  0.1\n",
      "GD:  13.401122498587917\n",
      "10173\n",
      "Polyak:  13.308054412396082\n",
      "Nesterov:  13.308043500912778\n",
      "6472\n",
      "Adagrad:  14.203125\n",
      "Newton:  14.271969731748074\n",
      "\n",
      "Time,  1\n",
      "GD:  13.401122498587917\n",
      "104063\n",
      "Polyak:  13.308054412396082\n",
      "Nesterov:  13.308043500912778\n",
      "69033\n",
      "Adagrad:  14.203125\n",
      "Newton:  14.271969731748074\n",
      "\n",
      "Time,  2\n",
      "GD:  13.401122498587917\n",
      "207707\n",
      "Polyak:  13.308054412396082\n",
      "Nesterov:  13.308043500912778\n",
      "139561\n",
      "Adagrad:  14.203125\n",
      "Newton:  14.271969731748074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "\n",
    "times = [.1, 1, 2]\n",
    "f = f3\n",
    "grad_f = grad_f3\n",
    "hess_f = hess_f3\n",
    "step = np.inf\n",
    "test_time(f, grad_f, hess_f, f3x0, step, times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b8f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a11a2447",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "1a412aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(N):\n",
    "    np.random.seed(0)\n",
    "    return np.array([np.array([i, i + np.random.random(1).item()]) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be77daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, steps=1000, base_lr=1e-3):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.mu = 0.05\n",
    "        self.steps = steps\n",
    "        self.lr = lambda x: base_lr * 0.99**x #if lr is None else lr\n",
    "\n",
    "    def gd(self, theta, loss_grad, lr_fn=None):\n",
    "        return gd(theta, loss_grad, self.lr, self.steps)\n",
    "    \n",
    "    def newton(self, theta, loss_grad, hess_grad, lr):\n",
    "        return newton(theta, loss_grad, hess_grad, self.steps, lr=self.lr)\n",
    "\n",
    "    def sgd(self, theta, grad_f, lr_fn):\n",
    "        return sgd(theta, grad_f, self.lr, n_steps=self.steps)\n",
    "\n",
    "    def bfgs(self, theta, grad_f, lr_fn):\n",
    "        return bfgs(theta, grad_f, self.lr, n_steps=self.steps)\n",
    "\n",
    "    def l_bfgs(self, theta, grad_f, lr_fn):\n",
    "        return l_bfgs(theta, grad_f, self.lr, n_steps=self.steps)\n",
    "\n",
    "\n",
    "    def fit(self, X, y, lr_fn=None, t=None):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Add bias column\n",
    "        X_aug = np.hstack([X, np.ones((n_samples, 1))])\n",
    "        theta = np.array([0,0])#np.random.rand(n_features + 1)\n",
    "\n",
    "        def loss_grad(theta):\n",
    "            print(theta)\n",
    "            preds = X_aug @ theta\n",
    "            grad = (2 / n_samples) * X_aug.T @ (preds - y)\n",
    "\n",
    "            # Print least squares\n",
    "            loss = np.mean((preds - y) ** 2)\n",
    "            print(\"Loss:\", loss)\n",
    "\n",
    "            return grad\n",
    "        \n",
    "        def sgd_loss_grad(theta):\n",
    "            i = np.random.randint(n_samples)\n",
    "            Xi = X_aug[i:i+1]  # shape (1, d+1)\n",
    "            yi = y[i]\n",
    "            \n",
    "            pred = Xi @ theta\n",
    "            \n",
    "            print(theta)\n",
    "            loss = np.mean((X_aug @ theta - y) ** 2)\n",
    "            print(\"Loss:\", loss)\n",
    "            \n",
    "            return 2 * Xi.T @ (pred - yi)  # shape (d+1,)\n",
    "\n",
    "        def loss_hessian(theta):\n",
    "            return (2 / n_samples) * X_aug.T @ X_aug\n",
    "\n",
    "        # theta_opt = self.gd(theta, loss_grad, self.lr)\n",
    "        theta_opt = self.newton(theta, loss_grad, loss_hessian, .5)\n",
    "        # theta_opt = self.sgd(theta, sgd_loss_grad, lr_fn)\n",
    "        # theta_opt = self.bfgs(theta, loss_grad, lr_fn)\n",
    "        # theta_opt = self.l_bfgs(theta, loss_grad, lr_fn)\n",
    "        \n",
    "        self.coef_ = theta_opt[:-1]\n",
    "        self.intercept_ = theta_opt[-1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return X @ self.coef_ + self.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "0ffa08a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "Loss: 3333333399.4732695\n",
      "[3.17402651e-01 7.96753399e-06]\n",
      "Loss: 1553141344.8653238\n",
      "[5.09614115e-01 1.30644941e-05]\n",
      "Loss: 801606913.8428366\n",
      "[1.36998646e+00 2.21586663e-05]\n",
      "Loss: 456274564.73433053\n",
      "[8.44101052e-01 1.60139248e-05]\n",
      "Loss: 81021529.60915413\n",
      "[9.89154150e-01 1.80983505e-05]\n",
      "Loss: 392645.65737526317\n",
      "[1.0054399e+00 1.8281666e-05]\n",
      "Loss: 98368.32059373456\n",
      "[1.00376954e+00 1.82403664e-05]\n",
      "Loss: 47175.67160862663\n",
      "[1.00348139e+00 1.82261622e-05]\n",
      "Loss: 40225.76661935088\n",
      "[1.00015656e+00 1.81800154e-05]\n",
      "Loss: 74.195202394368\n",
      "[1.00015644e+00 1.81799893e-05]\n",
      "Loss: 74.08264288668461\n",
      "[1.00015200e+00 1.81796989e-05]\n",
      "Loss: 69.73277238034764\n",
      "[1.00015074e+00 1.81795420e-05]\n",
      "Loss: 68.5279803347919\n",
      "[1.00014859e+00 1.81793537e-05]\n",
      "Loss: 66.49008165976012\n",
      "[9.99926101e-01 1.81769511e-05]\n",
      "Loss: 22.235948480517166\n",
      "[9.99967540e-01 1.81777301e-05]\n",
      "Loss: 5.470272917355287\n",
      "[9.99981968e-01 1.81780935e-05]\n",
      "Loss: 2.3196341969391443\n",
      "[1.00000354e+00 1.81784101e-05]\n",
      "Loss: 0.19764557255927728\n",
      "[1.00000424e+00 1.81784463e-05]\n",
      "Loss: 0.1806260056281594\n",
      "[1.00000136e+00 1.81784087e-05]\n",
      "Loss: 0.27105051208145986\n",
      "[1.00000360e+00 1.81785038e-05]\n",
      "Loss: 0.19599648126268857\n",
      "[1.00001068e+00 1.81785760e-05]\n",
      "Loss: 0.17846110012831895\n",
      "[9.99998172e-01 1.81784434e-05]\n",
      "Loss: 0.43565271765099145\n",
      "[1.00000029e+00 1.81785076e-05]\n",
      "Loss: 0.3187607532278258\n",
      "[1.00000315e+00 1.81785655e-05]\n",
      "Loss: 0.20853363719967924\n",
      "[1.00000346e+00 1.81785700e-05]\n",
      "Loss: 0.19968512439067998\n",
      "[1.00000508e+00 1.81786309e-05]\n",
      "Loss: 0.16468455564677667\n",
      "[1.00000632e+00 1.81787171e-05]\n",
      "Loss: 0.1497982217540828\n",
      "[1.00000858e+00 1.81788306e-05]\n",
      "Loss: 0.14883331768342248\n",
      "[1.00000925e+00 1.81788637e-05]\n",
      "Loss: 0.1551091189143452\n",
      "[1.00000964e+00 1.81789013e-05]\n",
      "Loss: 0.16021877043586982\n",
      "[1.00000333e+00 1.81788280e-05]\n",
      "Loss: 0.20319678953545886\n",
      "[1.00000350e+00 1.81788475e-05]\n",
      "Loss: 0.19873337266428145\n",
      "[1.00000409e+00 1.81788890e-05]\n",
      "Loss: 0.1840676692560787\n",
      "[1.00000711e+00 1.81789756e-05]\n",
      "Loss: 0.14557559503092973\n",
      "[9.99998330e-01 1.81788842e-05]\n",
      "Loss: 0.42592028476298144\n",
      "[1.00000204e+00 1.81790105e-05]\n",
      "Loss: 0.24462148488446986\n",
      "[1.00000280e+00 1.81790274e-05]\n",
      "Loss: 0.21907773588582663\n",
      "[1.00000528e+00 1.81790831e-05]\n",
      "Loss: 0.16159250123596428\n",
      "[1.00000733e+00 1.81791199e-05]\n",
      "Loss: 0.14514875179726153\n",
      "[1.00000542e+00 1.81790767e-05]\n",
      "Loss: 0.1595568107228686\n",
      "[1.00000589e+00 1.81791152e-05]\n",
      "Loss: 0.15380321902509556\n",
      "[1.00001072e+00 1.81791687e-05]\n",
      "Loss: 0.17931205628973526\n",
      "[1.00001001e+00 1.81791556e-05]\n",
      "Loss: 0.16585777989852013\n",
      "[1.00000940e+00 1.81791485e-05]\n",
      "Loss: 0.15697579013441593\n",
      "[1.00001038e+00 1.81792567e-05]\n",
      "Loss: 0.17255814868270608\n",
      "[1.00000883e+00 1.81792353e-05]\n",
      "Loss: 0.1508681883922473\n",
      "[1.00000814e+00 1.81792219e-05]\n",
      "Loss: 0.14637929102838956\n",
      "[1.00000911e+00 1.81792669e-05]\n",
      "Loss: 0.1535324354977349\n",
      "[1.00000669e+00 1.81792224e-05]\n",
      "Loss: 0.14726423860265495\n",
      "[1.00000733e+00 1.81792707e-05]\n",
      "Loss: 0.14515521661506803\n",
      "[1.00000257e+00 1.81792186e-05]\n",
      "Loss: 0.22621277465923054\n",
      "[1.00000278e+00 1.81792664e-05]\n",
      "Loss: 0.21949758057499458\n",
      "[1.00000295e+00 1.81793413e-05]\n",
      "Loss: 0.21438747762672558\n",
      "[1.00000089e+00 1.81793164e-05]\n",
      "Loss: 0.29098305830715787\n",
      "[1.00000228e+00 1.81793598e-05]\n",
      "Loss: 0.23609615218743213\n",
      "[1.00000450e+00 1.81793904e-05]\n",
      "Loss: 0.17518685986664514\n",
      "[1.00000553e+00 1.81794276e-05]\n",
      "Loss: 0.15808558837824443\n",
      "[1.00000538e+00 1.81794242e-05]\n",
      "Loss: 0.16011662703142812\n",
      "[1.00000750e+00 1.81794576e-05]\n",
      "Loss: 0.14504283158744496\n",
      "[1.00000763e+00 1.81794604e-05]\n",
      "Loss: 0.14508812494870596\n",
      "[1.00000908e+00 1.81795075e-05]\n",
      "Loss: 0.15331293975296054\n",
      "[1.00000555e+00 1.81794701e-05]\n",
      "Loss: 0.1578400835569201\n",
      "[1.00000697e+00 1.81795108e-05]\n",
      "Loss: 0.14601087194313225\n",
      "[1.00000760e+00 1.81795494e-05]\n",
      "Loss: 0.14506722776267453\n",
      "[1.00000907e+00 1.81795755e-05]\n",
      "Loss: 0.15314916618400973\n",
      "[1.00000459e+00 1.81795152e-05]\n",
      "Loss: 0.17345035793943855\n",
      "[1.00000819e+00 1.81795652e-05]\n",
      "Loss: 0.14659933315869236\n",
      "[1.00000489e+00 1.81795190e-05]\n",
      "Loss: 0.1679764185796728\n",
      "[1.00000766e+00 1.81795699e-05]\n",
      "Loss: 0.1451184024169713\n",
      "[1.00000497e+00 1.81795377e-05]\n",
      "Loss: 0.1665134100122939\n",
      "[1.00000178e+00 1.81795023e-05]\n",
      "Loss: 0.25460944501627747\n",
      "[1.00000595e+00 1.81795632e-05]\n",
      "Loss: 0.1531793136700334\n",
      "[1.00000497e+00 1.81795482e-05]\n",
      "Loss: 0.166595130437691\n",
      "[1.00000402e+00 1.81795306e-05]\n",
      "Loss: 0.18565574193614018\n",
      "[1.00000427e+00 1.81795430e-05]\n",
      "Loss: 0.18004239377699108\n",
      "[1.00000450e+00 1.81795522e-05]\n",
      "Loss: 0.17514971224038633\n",
      "[1.00000463e+00 1.81795809e-05]\n",
      "Loss: 0.1726586417664217\n",
      "[1.00000576e+00 1.81796232e-05]\n",
      "Loss: 0.15524053207563188\n",
      "[1.00000629e+00 1.81796365e-05]\n",
      "Loss: 0.14999854374497612\n",
      "[1.00000535e+00 1.81796145e-05]\n",
      "Loss: 0.16064649722730973\n",
      "[1.00000634e+00 1.81796729e-05]\n",
      "Loss: 0.14959105303643722\n",
      "[1.00000552e+00 1.81796569e-05]\n",
      "Loss: 0.1581996305557703\n",
      "[1.00000775e+00 1.81796803e-05]\n",
      "Loss: 0.14523976210340367\n",
      "[1.00000774e+00 1.81796788e-05]\n",
      "Loss: 0.145225326355656\n",
      "[1.00000889e+00 1.81796918e-05]\n",
      "Loss: 0.1514334243786211\n",
      "[1.00000884e+00 1.81796906e-05]\n",
      "Loss: 0.15095022814223819\n",
      "[1.00000970e+00 1.81797001e-05]\n",
      "Loss: 0.1610820258480739\n",
      "[1.00000994e+00 1.81797037e-05]\n",
      "Loss: 0.16466039557125878\n",
      "[1.00000728e+00 1.81796702e-05]\n",
      "Loss: 0.14521118572341082\n",
      "[1.00000506e+00 1.81796474e-05]\n",
      "Loss: 0.16509712248774366\n",
      "[1.00000513e+00 1.81796727e-05]\n",
      "Loss: 0.16394262926025832\n",
      "[1.00000798e+00 1.81797303e-05]\n",
      "Loss: 0.1457684035602597\n",
      "[1.00000438e+00 1.81796911e-05]\n",
      "Loss: 0.17760626833458737\n",
      "[1.00000564e+00 1.81797053e-05]\n",
      "Loss: 0.15668447777924735\n",
      "[1.00000796e+00 1.81797456e-05]\n",
      "Loss: 0.14572995749579795\n",
      "[1.00000916e+00 1.81797599e-05]\n",
      "Loss: 0.1541712197667918\n",
      "[1.00001100e+00 1.81798013e-05]\n",
      "Loss: 0.18575914534987834\n",
      "[1.00000879e+00 1.81797782e-05]\n",
      "Loss: 0.1505029436665777\n",
      "[1.00001025e+00 1.81798301e-05]\n",
      "Loss: 0.17005104618876266\n",
      "Time: 0.05805087089538574\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(base_lr=1e-10, steps=100)\n",
    "\n",
    "data = get_data(100000)\n",
    "\n",
    "start = time.time()\n",
    "model.fit(data[:,0].reshape((-1, 1)), data[:,1])\n",
    "print(\"Time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "dab8db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00001135]), np.float64(1.817986535481756e-05))"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "f29dca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28d876c5a50>]"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "\n",
    "x_vals = np.sort(data[:, 0])\n",
    "y_vals = model.predict(x_vals.reshape(-1, 1))\n",
    "\n",
    "plt.plot(x_vals, y_vals, color='red')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
