{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "d7dbea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "8caae505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    x,y,z = x\n",
    "    return (x - z)**2 + (2*y + z)**2 + (4*x - 2*y + z)**2 + x + y\n",
    "\n",
    "def grad_f1(x):\n",
    "    x,y,z = x[0], x[1], x[2]\n",
    "    dx = 2*(x - z) + 8*(4*x - 2*y + z) + 1\n",
    "    dy = 4*(2*y + z) - 4*(4*x - 2*y + z) + 1\n",
    "    dz = -2*(x - z) + 2*(2*y + z) + 2*(4*x - 2*y + z)\n",
    "    \n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def hess_f1(x):\n",
    "    dxx = 34 # 2 + 32\n",
    "    dxy = -16\n",
    "    dxz = 6 #-2 + 8\n",
    "    dyy = 16\n",
    "    dyz = 0\n",
    "    dzz = 6\n",
    "    \n",
    "    return np.array([[dxx, dxy, dxz], [dxy, dyy, dyz], [dxz, dyz, dzz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "08eaaa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0),\n",
       " array([1, 1, 0]),\n",
       " array([[ 34, -16,   6],\n",
       "        [-16,  16,   0],\n",
       "        [  6,   0,   6]]))"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_x1 = np.array([0,0,0]) \n",
    "f1(f1_x1), grad_f1(f1_x1), hess_f1(f1_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "c45d29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    x,y,z = x\n",
    "    return (x - 1)**2 + (y - 1)**2 + 100*(y-x**2)**2 + 100*(z-y**2)**2\n",
    "\n",
    "def grad_f2(x):\n",
    "    x,y,z = x[0], x[1], x[2]\n",
    "    dx = 2*x - 2 - 400 * x * y + 400 * x**3\n",
    "    dy = 2*y - 2 + 200 * (y - x**2) - 400*z*y + 400 * y**3\n",
    "    dz = 200 * (z - y**2)\n",
    "        \n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def hess_f2(x):\n",
    "    x,y,z = x[0], x[1], x[2]\n",
    "    \n",
    "    dxx = 2 - 400 * y + 1200 * x**2\n",
    "    dxy = -400 * x\n",
    "    dxz = 0\n",
    "    dyy = 2 + 200 - 400 * z + 1200 * y**2\n",
    "    dyz = -400 * y\n",
    "    dzz = 200\n",
    "    return np.array([[dxx, dxy, dxz], [dxy, dyy, dyz], [dxz, dyz, dzz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "6fff7db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(11.6),\n",
       " array([115.6,  67.6, -48. ]),\n",
       " array([[1250., -480.,    0.],\n",
       "        [-480., 1450., -480.],\n",
       "        [   0., -480.,  200.]]))"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2_x1 = np.array([1.2, 1.2, 1.2])\n",
    "f2(f2_x1), grad_f2(f2_x1), hess_f2(f2_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "b2ac8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    x,y = x\n",
    "    return (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "\n",
    "def grad_f3(x):\n",
    "    x,y = x[0], x[1]\n",
    "    \n",
    "    dx = -12.75 * 6*x + 3*y - 4*x*y - 2*x*y**2 + 4.5*y**2 + 2*x*y**4 - 4*x*y**3 + 5.25 * y**3 + 2*x*y**6\n",
    "    dy = 3*x + 9*y*x - 4*x**2*y - 2*x**2 + 15.75*y**2 *x + 2*x**2 * y - 6 * x**2 * y**2 + 4*x**3*y**3 + 6*x**2*y**5\n",
    "    \n",
    "    return np.array([dx, dy])\n",
    "\n",
    "def hess_f3(x):\n",
    "    x,y = x[0], x[1]\n",
    "    \n",
    "    dxx = 6 - 4*y - 2*y**2 + 2*y**4 - 4*y**3 + 2*y**6\n",
    "    dxy = 3 - 4*x - 4*x*y + 9*y + 8*x*y**3 - 12*x*y**2 + 15.75*y**2 + 12*x*y**5\n",
    "    dyy = 9*x - 4*x**2 + 31.5*y*x + 2*x**2 - 12*x**2*y + 12*x**2*y**2 + 30*x**2*y**4\n",
    "    return np.array([[dxx, dxy], [dxy, dyy]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "b6582d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(14.203125),\n",
       " array([-69.75,  27.75]),\n",
       " array([[ 0.  , 27.75],\n",
       "        [27.75, 68.5 ]]))"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3_x1 = np.array([1,1])\n",
    "f3(f3_x1), grad_f3(f3_x1), hess_f3(f3_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "bdd8fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 1e-5 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(x, grad_f, lr_fn, n_steps, t=None):\n",
    "    \n",
    "    if t is not None:\n",
    "        i = 0\n",
    "        start = time.perf_counter()\n",
    "        while time.perf_counter() - start < t:\n",
    "            x = x - lr_fn(i) * grad_f(x)\n",
    "            i += 1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            x = x - lr_fn(i) * grad_f(x)\n",
    "        \n",
    "    return x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be5673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def polyak(x: np.ndarray, grad_f, lr_fn, mu, n_steps, t=None):\n",
    "    x_prev = x\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            dx = grad_f(x)\n",
    "            x_new = x - lr_fn(i) * dx  + mu * (x - x_prev)\n",
    "        \n",
    "            x_prev = np.copy(x)\n",
    "            x = x_new\n",
    "            i+=1\n",
    "        print(i)\n",
    "        return x\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            dx = grad_f(x)\n",
    "            x_new = x - lr_fn(i) * dx  + mu * (x - x_prev)\n",
    "        \n",
    "            x_prev = x\n",
    "            x = x_new\n",
    "            i+=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(x, f, grad_f, lr_fn, mu, n_steps, t=None):\n",
    "    x_prev = np.copy(x)\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            x_ahead = x + mu * (x - x_prev)\n",
    "            dx = grad_f(x_ahead)\n",
    "            x_new = x - lr_fn(i) * dx + mu * (x - x_prev)\n",
    "    \n",
    "            x_prev = x\n",
    "            x = x_new\n",
    "            i+=1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            x_ahead = x + mu * (x - x_prev)\n",
    "            dx = grad_f(x_ahead)\n",
    "            x_new = x - lr_fn(i) * dx + mu * (x - x_prev)\n",
    "    \n",
    "            x_prev = x\n",
    "            x = x_new\n",
    "            i+=1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fa1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad(x, grad_f, lr_fn, n_steps, eps=1e-8, t=None):\n",
    "    x = np.array(x, dtype=float)\n",
    "    n = len(x)\n",
    "    \n",
    "    grad_sq_sum = np.zeros(n)\n",
    "    \n",
    "     \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            grad = np.array(grad_f(x))\n",
    "        \n",
    "            # Accumulate squared gradients\n",
    "            grad_sq_sum += grad ** 2\n",
    "            \n",
    "            # Compute D_k^{-1/2}\n",
    "            D_inv_sqrt = np.diag(1.0 / (np.sqrt(grad_sq_sum) + eps))\n",
    "            # Adaptive step\n",
    "            step = lr_fn(i) * D_inv_sqrt @ grad\n",
    "            x_new = x - step\n",
    "            \n",
    "            x = x_new\n",
    "            i+= 1\n",
    "        print(i)\n",
    "        return x\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            grad = np.array(grad_f(x))\n",
    "            \n",
    "            # Accumulate squared gradients\n",
    "            grad_sq_sum += grad ** 2\n",
    "            \n",
    "            # Compute D_k^{-1/2}\n",
    "            D_inv_sqrt = np.diag(1.0 / (np.sqrt(grad_sq_sum) + eps))\n",
    "            \n",
    "            # Adaptive step\n",
    "            step = lr_fn(i) * D_inv_sqrt @ grad\n",
    "            x_new = x - step\n",
    "            \n",
    "            x = x_new\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "93b767ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.0002721217099388247)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(adagrad(f1_x1, grad_f1, learning_rate, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94603437",
   "metadata": {},
   "source": [
    "Newton and BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "e15c33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_positive_definite(H):\n",
    "    try:\n",
    "        np.linalg.cholesky(H)\n",
    "        return True\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4858f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(x0, grad_f, hess_f, n_steps=100, t=None, lr=None):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.perf_counter()\n",
    "        i = 0\n",
    "        while time.perf_counter() - start < t:\n",
    "            grad = np.array(grad_f(x))\n",
    "            hess = np.array(hess_f(x))\n",
    "            \n",
    "            hess_inv = np.linalg.inv(hess)\n",
    "            \n",
    "            lr = lr if lr is not None else learning_rate(i)\n",
    "            # Compute Newton step\n",
    "            x = x - learning_rate(i) * hess_inv @ grad\n",
    "            i += 1\n",
    "\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            grad = np.array(grad_f(x))\n",
    "            grad = np.clip(grad, -10, 10)\n",
    "\n",
    "            hess = np.array(hess_f(x)) + 1e-4 * np.eye(len(x))\n",
    "            \n",
    "            hess_inv = np.linalg.inv(hess)\n",
    "            \n",
    "            # Compute Newton step\n",
    "            x = x - hess_inv @ grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "e96eed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum3(f2), print(\"Newton: \", f2(newton(np.array([0,0,0]), grad_f1, hess_f1, 100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "e9266eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x, grad_f, lr_fn, n_steps=100, t=None):\n",
    "    x = np.array(x, dtype=float)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        grad = grad_f(x) \n",
    "        x = x - lr_fn(i) * grad\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb9f53",
   "metadata": {},
   "source": [
    "### BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "d97b3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs(x, grad_f, lr_fn, n_steps, t=None):\n",
    "    B = np.eye(len(x)) * 0.0001\n",
    "    grad = grad_f(x)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        x_new = x - B @ grad\n",
    "        grad_new = grad_f(x_new)\n",
    "\n",
    "        delta = (x_new - x).reshape((-1, 1))\n",
    "        gamma = (grad_new - grad).reshape((-1, 1))\n",
    "        rho = 1.0 / (delta.T @ gamma + 1e-10)\n",
    "\n",
    "        if np.isfinite(rho) and rho > 0:\n",
    "            I = np.eye(len(x))\n",
    "            B = (I - rho * delta @ gamma.T) @ B @ (I - rho * gamma @ delta.T) + rho * delta @ delta.T\n",
    "\n",
    "        x, grad = x_new, grad_new\n",
    "        # print(f\"x: {x.flatten()}, grad norm: {np.linalg.norm(grad)}\")\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "fcabe647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfgs(np.array([1,0,0]), grad_f1, hess_f1, 100), minimum3(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "ee979b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f3(bfgs(np.array([1,0]), grad_f3, hess_f3, 100)), minimum2(f3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "f75232aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfgs(np.array([1,0,0]), grad_f2, hess_f2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "888c851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def l_bfgs(x, grad_f, m=10, n_steps=100):\n",
    "    grad = grad_f(x).reshape(-1, 1)\n",
    "\n",
    "    B = []      \n",
    "    gamma = []  \n",
    "    rho = []  \n",
    "\n",
    "    for step in range(n_steps):\n",
    "        q = grad.copy()\n",
    "        alpha = []\n",
    "\n",
    "        for i in reversed(range(len(B))):\n",
    "            s_i, y_i, rho_i = B[i], gamma[i], rho[i]\n",
    "            alpha_i = rho_i * (s_i.T @ q).item()\n",
    "            alpha.append(alpha_i)\n",
    "            q = q - alpha_i * y_i\n",
    "\n",
    "        if B:\n",
    "            s_last, y_last = B[-1], gamma[-1]\n",
    "            H0 = (s_last.T @ y_last).item() / (y_last.T @ y_last).item()\n",
    "            r = H0 * q\n",
    "        else:\n",
    "            r = q\n",
    "\n",
    "        for i in range(len(B)):\n",
    "            s_i, y_i, rho_i = B[i], gamma[i], rho[i]\n",
    "            beta_i = rho_i * (y_i.T @ r).item()\n",
    "            r = r + s_i * (alpha[-(i + 1)] - beta_i)\n",
    "\n",
    "        x_new = x - r.flatten()\n",
    "        grad_new = grad_f(x_new).reshape(-1, 1)\n",
    "\n",
    "        s_k = (x_new - x).reshape(-1, 1)\n",
    "        y_k = (grad_new - grad).reshape(-1, 1)\n",
    "        ys = (y_k.T @ s_k).item()\n",
    "\n",
    "        if ys > 1e-10:  # safeguard\n",
    "            rho_k = 1.0 / ys\n",
    "            if len(B) == m:\n",
    "                B.pop(0)\n",
    "                gamma.pop(0)\n",
    "                rho.pop(0)\n",
    "            B.append(s_k)\n",
    "            gamma.append(y_k)\n",
    "            rho.append(rho_k)\n",
    "\n",
    "        x, grad = x_new, grad_new\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "c1928654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.546678239835239e-31)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2(bfgs(np.array([0,0,0]), grad_f2, hess_f2, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "4aa5a7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7949332 , 0.63239939, 0.4028514 ])"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_bfgs(np.array([0,0,0]), grad_f2, hess_f2, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "18e99798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2(np.array([1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "6e1becf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum3(f2), print(\"BFGS: \", bfgs(np.array([0,0,0]), grad_f2, hess_f2, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063c60a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "2eb0fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum2(f):\n",
    "    \"\"\"Finds approximate minimum of f(x)\"\"\"\n",
    "    xs = np.linspace(-3, 3, 1000)\n",
    "    ys = np.linspace(-3, 3, 1000)\n",
    "    X, Y = np.meshgrid(xs, ys)  \n",
    "    Z = f(np.array([X, Y]))  \n",
    "    \n",
    "    min_idx = np.unravel_index(np.argmin(Z), Z.shape)  \n",
    "    bx, by, bz = X[min_idx], Y[min_idx], Z[min_idx]\n",
    "    return np.array([bx, by, bz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "bf59e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum3(f):\n",
    "    \"\"\"Finds approximate minimum of f(x)\"\"\"\n",
    "    xs = np.linspace(-3, 3, 100)\n",
    "    ys = np.linspace(-3, 3, 100)\n",
    "    zs = np.linspace(-3, 3, 100)\n",
    "    \n",
    "    X, Y, Z = np.meshgrid(xs, ys, zs)  \n",
    "    W = f(np.array([X, Y, Z]))  \n",
    "    \n",
    "    min_idx = np.unravel_index(np.argmin(W), W.shape)  \n",
    "    bx, by, bz, bw = X[min_idx], Y[min_idx], Z[min_idx], W[min_idx]\n",
    "    return np.array([bx, by, bz, bw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "8be12379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 minimum: [-0.15151515 -0.21212121  0.15151515 -0.19651056]\n",
      "f2 minimum: [1. 1. 1. 0.]\n",
      "f3 minimum: [3.00000000e+00 5.01501502e-01 5.21242614e-05]\n"
     ]
    }
   ],
   "source": [
    "f1_xopt = minimum3(f1)\n",
    "f2_xopt = minimum3(f2)\n",
    "f3_xopt = minimum2(f3)\n",
    "print(\"f1 minimum:\", f1_xopt)\n",
    "print(\"f2 minimum:\", f2_xopt)\n",
    "print(\"f3 minimum:\", f3_xopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "0293c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum(f):\n",
    "    if f == f1 or f == f2:\n",
    "        return minimum3(f)\n",
    "    return minimum2(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "cac05bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_steps(f, grad_f, hess_f, x0, steps):\n",
    "    print(\"True minimum\", minimum(f)[-1], \"at \", minimum(f)[:-1])\n",
    "    for step in steps:\n",
    "        print(\"Steps, \", step)\n",
    "        print(\"GD: \", f(gd(x0, grad_f, learning_rate, step)))\n",
    "        print(\"Polyak: \", f(polyak(x0, grad_f, learning_rate, 0.1, step)))\n",
    "        print(\"Nesterov: \", f(nesterov(x0, f, grad_f, learning_rate, 0.1, step)))\n",
    "        print(\"Adagrad: \", f(adagrad(x0, grad_f, learning_rate, step)))\n",
    "        print(\"Newton: \", f(newton(x0, grad_f, hess_f, step)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "f9009436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 5.2124261432689534e-05 at  [3.        0.5015015]\n",
      "Steps,  2\n",
      "GD:  766.5966317471315\n",
      "Polyak:  317.3669399261159\n",
      "Nesterov:  337.8935150873536\n",
      "Adagrad:  174808.13322562698\n",
      "Newton:  174787.39590967732\n",
      "\n",
      "Steps,  5\n",
      "GD:  573.3181260243873\n",
      "Polyak:  234.18423832681148\n",
      "Nesterov:  251.2675637282102\n",
      "Adagrad:  174803.57841077237\n",
      "Newton:  174748.44359514368\n",
      "\n",
      "Steps,  10\n",
      "GD:  391.01982633597123\n",
      "Polyak:  180.14097490210202\n",
      "Nesterov:  191.6422296038764\n",
      "Adagrad:  174798.44086632194\n",
      "Newton:  174683.519713985\n",
      "\n",
      "Steps,  100\n",
      "GD:  41.4483127130285\n",
      "Polyak:  27.34367484514155\n",
      "Nesterov:  28.13095223694685\n",
      "Adagrad:  174771.4872038422\n",
      "Newton:  173514.16284713175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1x0 = np.array([0, 0, 0])\n",
    "f1x1 = np.array([1, 1, 0])\n",
    "f2x0 = np.array([1.2, 1.2, 1.2])\n",
    "f2x1 = np.array([-1, 1.2, 1.2])\n",
    "f3x0 = np.array([1,1])\n",
    "f3x1 = np.array([4.5, 4.5])\n",
    "\n",
    "steps = [2, 5, 10, 100]\n",
    "f = f3\n",
    "grad_f = grad_f3\n",
    "hess_f = hess_f3\n",
    "\n",
    "test_steps(f, grad_f, hess_f, f3x1, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "9e10ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_steps(f, grad_f, hess_f, f1x1, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "f765bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 0.001 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "b8c15a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2 1.2 1.2]\n",
      "True minimum 0.0 at  [1. 1. 1.]\n",
      "Steps,  2\n",
      "GD:  0.04360204395724923\n",
      "Polyak:  0.029878998002554\n",
      "Nesterov:  0.02673542046251252\n",
      "Adagrad:  11.212136336931973\n",
      "Newton:  6.486502125611452\n",
      "\n",
      "Steps,  5\n",
      "GD:  0.018222098858116126\n",
      "Polyak:  0.018111957810387373\n",
      "Nesterov:  0.01825287933581621\n",
      "Adagrad:  10.884354328434366\n",
      "Newton:  7.82723804484026\n",
      "\n",
      "Steps,  10\n",
      "GD:  0.018114796902295175\n",
      "Polyak:  0.018026193463732743\n",
      "Nesterov:  0.018042756516489775\n",
      "Adagrad:  10.524769246910026\n",
      "Newton:  32.57752757205745\n",
      "\n",
      "Steps,  100\n",
      "GD:  0.017367128919067866\n",
      "Polyak:  0.017199958422235238\n",
      "Nesterov:  0.01721471000097329\n",
      "Adagrad:  8.795304386701261\n",
      "Newton:  3523.7010595623265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = f2\n",
    "grad_f = grad_f2\n",
    "hess_f = hess_f2\n",
    "\n",
    "print(f2x0)\n",
    "test_steps(f, grad_f, hess_f, f2x0, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "5f03af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 0.0 at  [1. 1. 1.]\n",
      "Steps,  2\n",
      "GD:  5.229583521614642\n",
      "Polyak:  4.478010157939434\n",
      "Nesterov:  5.73751903199277\n",
      "Adagrad:  13.332066264049159\n",
      "Newton:  13.335799674114092\n",
      "\n",
      "Steps,  5\n",
      "GD:  4.227341057837024\n",
      "Polyak:  4.206751434677671\n",
      "Nesterov:  4.320012289083483\n",
      "Adagrad:  12.938862640765567\n",
      "Newton:  20.325429321856642\n",
      "\n",
      "Steps,  10\n",
      "GD:  4.20332860424492\n",
      "Polyak:  4.202417733869578\n",
      "Nesterov:  4.200249207030582\n",
      "Adagrad:  12.50992146936056\n",
      "Newton:  47.99574664249103\n",
      "\n",
      "Steps,  100\n",
      "GD:  4.162038855665383\n",
      "Polyak:  4.156500293012095\n",
      "Nesterov:  4.153848805697812\n",
      "Adagrad:  10.487659531267003\n",
      "Newton:  3589.711514754642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_steps(f, grad_f, hess_f, f2x1, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "81bf0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 0.00002 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "2e04b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 5.2124261432689534e-05 at  [3.        0.5015015]\n",
      "Steps,  2\n",
      "GD:  14.172429833366285\n",
      "Polyak:  14.170885263029238\n",
      "Nesterov:  14.170884914992083\n",
      "Adagrad:  14.20218149283947\n",
      "Newton:  14.196702713495865\n",
      "\n",
      "Steps,  5\n",
      "GD:  14.127347739705236\n",
      "Polyak:  14.120737629445859\n",
      "Nesterov:  14.120735973611062\n",
      "Adagrad:  14.201359799053826\n",
      "Newton:  14.24856149388566\n",
      "\n",
      "Steps,  10\n",
      "GD:  14.054718428955553\n",
      "Polyak:  14.03986085307536\n",
      "Nesterov:  14.039856892179442\n",
      "Adagrad:  14.200432977586338\n",
      "Newton:  14.203125211194463\n",
      "\n",
      "Steps,  100\n",
      "GD:  13.175395207257178\n",
      "Polyak:  13.055663113603089\n",
      "Nesterov:  13.055622129439703\n",
      "Adagrad:  14.19557041905663\n",
      "Newton:  14.203125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = f3\n",
    "grad_f = grad_f3\n",
    "hess_f = hess_f3\n",
    "\n",
    "test_steps(f, grad_f, hess_f, f3x0, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "fa674423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 5.2124261432689534e-05 at  [3.        0.5015015]\n",
      "Steps,  2\n",
      "GD:  12.43281596089588\n",
      "Polyak:  48.929151079532424\n",
      "Nesterov:  48.26973667113842\n",
      "Adagrad:  174802.90334024787\n",
      "Newton:  174787.39590967732\n",
      "\n",
      "Steps,  5\n",
      "GD:  12.513887697772656\n",
      "Polyak:  55.536960158281005\n",
      "Nesterov:  54.584161483235654\n",
      "Adagrad:  174793.794192175\n",
      "Newton:  174748.44359514368\n",
      "\n",
      "Steps,  10\n",
      "GD:  12.646195813283086\n",
      "Polyak:  51.47237658916009\n",
      "Nesterov:  50.672956432744265\n",
      "Adagrad:  174783.51999161392\n",
      "Newton:  174683.519713985\n",
      "\n",
      "Steps,  100\n",
      "GD:  14.418963181952417\n",
      "Polyak:  30.205778485525904\n",
      "Nesterov:  30.018365665044307\n",
      "Adagrad:  174729.62288745432\n",
      "Newton:  173514.16284713175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_steps(f, grad_f, hess_f, f3x1, steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "6b4c5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time(f, grad_f, hess_f, x0, step, times):\n",
    "    print(\"True minimum\", f2_xopt[-1])\n",
    "    for _time in times:\n",
    "        print(\"Time, \", _time)\n",
    "        print(\"GD: \", f(gd(x0, grad_f, learning_rate, step, t=_time)))\n",
    "        print(\"Polyak: \", f(polyak(x0, grad_f, learning_rate, 0.1, step, t=_time)))\n",
    "        print(\"Nesterov: \", f(nesterov(x0, f, grad_f, learning_rate, 0.1, step, t=_time)))\n",
    "        print(\"Adagrad: \", f(adagrad(x0, grad_f, learning_rate, 0.1, step, t=_time)))\n",
    "        print(\"Newton: \", f(newton(x0, grad_f, hess_f, step, t=_time)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "6f651e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 1e-7 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "b7546db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum 0.0\n",
      "Time,  0.1\n",
      "GD:  14.195421207878482\n",
      "10378\n",
      "Polyak:  14.194564840525787\n",
      "Nesterov:  14.194564839986239\n",
      "6874\n",
      "Adagrad:  14.203125\n",
      "Newton:  14.20382240803205\n",
      "\n",
      "Time,  1\n",
      "GD:  14.195421207878482\n",
      "101718\n",
      "Polyak:  14.194564840525787\n",
      "Nesterov:  14.194564839986239\n",
      "67981\n",
      "Adagrad:  14.203125\n",
      "Newton:  14.20382240803205\n",
      "\n",
      "Time,  2\n",
      "GD:  14.195421207878482\n",
      "194872\n",
      "Polyak:  14.194564840525787\n",
      "Nesterov:  14.194564839986239\n",
      "133910\n",
      "Adagrad:  14.203125\n",
      "Newton:  14.20382240803205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "\n",
    "times = [.1, 1, 2]\n",
    "f = f3\n",
    "grad_f = grad_f3\n",
    "hess_f = hess_f3\n",
    "step = np.inf\n",
    "test_time(f, grad_f, hess_f, f3x0, step, times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b8f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a11a2447",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "1a412aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(N):\n",
    "    np.random.seed(0)\n",
    "    return np.array([np.array([i, i + np.random.random(1).item()]) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "4be77daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, base_lr=1e-3):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.mu = 0.05\n",
    "        self.steps = 1000\n",
    "        self.lr = lambda x: base_lr * 0.99**x #if lr is None else lr\n",
    "\n",
    "    def gd(self, theta, loss_grad, lr_fn=None):\n",
    "        return gd(theta, loss_grad, self.lr, self.steps)\n",
    "    \n",
    "    def newton(self, theta, loss_grad, hess_grad, lr):\n",
    "        return newton(theta, loss_grad, hess_grad, self.steps, lr=self.lr)\n",
    "\n",
    "    def sgd(self, theta, grad_f, lr_fn):\n",
    "        return sgd(theta, grad_f, self.lr, n_steps=self.steps)\n",
    "\n",
    "    def bfgs(self, theta, grad_f, lr_fn):\n",
    "        return bfgs(theta, grad_f, self.lr, n_steps=self.steps)\n",
    "\n",
    "    def l_bfgs(self, theta, grad_f, lr_fn):\n",
    "        return l_bfgs(theta, grad_f, self.lr, n_steps=self.steps)\n",
    "\n",
    "\n",
    "    def fit(self, X, y, lr_fn=None, t=None):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Add bias column\n",
    "        X_aug = np.hstack([X, np.ones((n_samples, 1))])\n",
    "        theta = np.array([-1,-1])#np.random.rand(n_features + 1)\n",
    "\n",
    "        def loss_grad(theta):\n",
    "            print(theta)\n",
    "            preds = X_aug @ theta\n",
    "            grad = (2 / n_samples) * X_aug.T @ (preds - y)\n",
    "\n",
    "            # Print least squares\n",
    "            loss = np.mean((preds - y) ** 2)\n",
    "            print(\"Loss:\", loss)\n",
    "\n",
    "            return grad\n",
    "        \n",
    "        def sgd_loss_grad(theta):\n",
    "            i = np.random.randint(n_samples)\n",
    "            Xi = X_aug[i:i+1]  # shape (1, d+1)\n",
    "            yi = y[i]\n",
    "            pred = Xi @ theta\n",
    "            \n",
    "            print(theta)\n",
    "            loss = np.mean((X_aug @ theta - y) ** 2)\n",
    "            print(\"Loss:\", loss)\n",
    "            \n",
    "            return 2 * Xi.T @ (pred - yi)  # shape (d+1,)\n",
    "\n",
    "        def loss_hessian(theta):\n",
    "            return (2 / n_samples) * X_aug.T @ X_aug\n",
    "\n",
    "        # theta_opt = self.gd(theta, loss_grad, self.lr)\n",
    "        # theta_opt = self.newton(theta, loss_grad, loss_hessian, .5)\n",
    "        theta_opt = self.sgd(theta, sgd_loss_grad, lr_fn)\n",
    "        # theta_opt = self.bfgs(theta, loss_grad, lr_fn)\n",
    "        # theta_opt = self.l_bfgs(theta, loss_grad, lr_fn)\n",
    "        \n",
    "        self.coef_ = theta_opt[:-1]\n",
    "        self.intercept_ = theta_opt[-1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return X @ self.coef_ + self.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "0ffa08a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.]\n",
      "Loss: 1333334334653.79\n",
      "[77.16059223 -0.99982318]\n",
      "Loss: 1933475588615909.2\n",
      "[-166.73985114   -1.00174099]\n",
      "Loss: 9378872070671076.0\n",
      "[ 1.38000755e+04 -9.80311240e-01]\n",
      "Loss: 6.347139967581349e+19\n",
      "[-2.33843496e+06 -3.49007672e+00]\n",
      "Loss: 1.8227581739727496e+24\n",
      "[3.22030875e+08 3.78250219e+02]\n",
      "Loss: 3.456790951785493e+28\n",
      "[-3.13911481e+08 -5.86284223e+03]\n",
      "Loss: 3.2846756847486167e+28\n",
      "[2.59208535e+10 3.35159844e+04]\n",
      "Loss: 2.2396321228662346e+32\n",
      "[-3.05235652e+12 -3.82319152e+06]\n",
      "Loss: 3.1056221119337696e+36\n",
      "[3.60017966e+14 4.48416609e+08]\n",
      "Loss: 4.320424702315949e+40\n",
      "[-7.01895843e+13 -4.87112823e+09]\n",
      "Loss: 1.642190120270997e+39\n",
      "[2.72328511e+15 1.08411737e+09]\n",
      "Loss: 2.4720902256444176e+42\n",
      "[-2.84511121e+17 -3.73175831e+11]\n",
      "Loss: 2.698215210036352e+46\n",
      "[2.51528075e+19 3.54456589e+13]\n",
      "Loss: 2.108875914089767e+50\n",
      "[-1.79241530e+21 -2.79713538e+15]\n",
      "Loss: 1.0709159315767491e+54\n",
      "[2.73412305e+23 2.89960763e+17]\n",
      "Loss: 2.4918058777695632e+58\n",
      "[-1.25041530e+25 -2.42239184e+19]\n",
      "Loss: 5.211786944576704e+61\n",
      "[1.86081337e+27 1.97301211e+21]\n",
      "Loss: 1.1542070643107932e+66\n",
      "[-1.78878897e+29 -2.36145056e+23]\n",
      "Loss: 1.066587054838339e+70\n",
      "[7.77091143e+30 1.51698282e+25]\n",
      "Loss: 2.0128991300394506e+73\n",
      "[-2.11551266e+32 -5.15502693e+26]\n",
      "Loss: 1.491795695378936e+76\n",
      "[1.94578358e+34 2.55742626e+28]\n",
      "Loss: 1.2620226920359496e+80\n",
      "[-4.68571349e+35 -1.21452002e+30]\n",
      "Loss: 7.318625986204349e+82\n",
      "[2.32926697e+36 1.32832535e+31]\n",
      "Loss: 1.808492163034446e+84\n",
      "[-8.25359147e+36 -4.92672578e+31]\n",
      "Loss: 2.2707223337891824e+85\n",
      "[2.74372871e+38 5.56164542e+32]\n",
      "Loss: 2.5093453073152254e+88\n",
      "[-7.14762892e+39 -1.72424436e+34]\n",
      "Loss: 1.7029507508430922e+91\n",
      "[1.89186826e+41 4.47649250e+35]\n",
      "Loss: 1.1930533788147676e+94\n",
      "[-1.24147701e+43 -1.86196431e+37]\n",
      "Loss: 5.137542842632263e+97\n",
      "[3.71698372e+42 1.55247635e+38]\n",
      "Loss: 4.605315743766412e+96\n",
      "[-1.75133605e+43  4.66553014e+37]\n",
      "Loss: 1.0223911185099571e+98\n",
      "[1.04563183e+45 1.70633373e+39]\n",
      "Loss: 3.644480954815525e+101\n",
      "[-9.28625029e+46 -1.18216400e+41]\n",
      "Loss: 2.874477171443447e+105\n",
      "[-3.62102151e+46  7.55171217e+41]\n",
      "Loss: 4.370592377387482e+104\n",
      "[9.21609119e+47 2.98644602e+42]\n",
      "Loss: 2.8312069800887344e+107\n",
      "[-3.38495758e+49 -6.44968728e+43]\n",
      "Loss: 3.819306877144024e+110\n",
      "[3.54068780e+51 4.06139118e+45]\n",
      "Loss: 4.178817105676345e+114\n",
      "[-1.25643886e+53 -2.48343430e+47]\n",
      "Loss: 5.262120778623223e+117\n",
      "[4.81078397e+54 8.99955763e+48]\n",
      "Loss: 7.714535906361191e+120\n",
      "[-6.47140195e+56 -6.45333850e+50]\n",
      "Loss: 1.3959660139879441e+125\n",
      "[2.46363728e+58 4.63786250e+52]\n",
      "Loss: 2.0231665220021858e+128\n",
      "[-1.67921226e+59 -7.50308143e+53]\n",
      "Loss: 9.399165249899639e+129\n",
      "[1.46888180e+61 1.74278985e+55]\n",
      "Loss: 7.192035027145616e+133\n",
      "[ 1.09972842e+61 -6.68960503e+55]\n",
      "Loss: 4.0313359296245064e+133\n",
      "[-7.34673838e+62 -1.09867834e+57]\n",
      "Loss: 1.7991494609209482e+137\n",
      "[5.76294325e+64 7.31364539e+58]\n",
      "Loss: 1.1070488372165139e+141\n",
      "[-7.36560573e+65 -2.34005210e+60]\n",
      "Loss: 1.8084022127791948e+143\n",
      "[4.67692900e+67 6.40498849e+61]\n",
      "Loss: 7.291210680700043e+146\n",
      "[-2.75293080e+68 -1.30649244e+63]\n",
      "Loss: 2.5262055447225472e+148\n",
      "[6.09106618e+69 1.34031761e+64]\n",
      "Loss: 1.2367010512214867e+151\n",
      "[-2.98864312e+71 -4.63073968e+65]\n",
      "Loss: 2.977324768560553e+154\n",
      "[1.01987337e+73 1.90208695e+67]\n",
      "Loss: 3.4671337983466563e+157\n",
      "[-1.02729935e+75 -1.10682578e+69]\n",
      "Loss: 3.517807892267865e+161\n",
      "[5.94164350e+75 2.80313269e+70]\n",
      "Loss: 1.17676914920905e+163\n",
      "[-1.48092974e+77 -2.99769555e+71]\n",
      "Loss: 7.310498699070221e+165\n",
      "[5.44748227e+78 9.51442921e+72]\n",
      "Loss: 9.891672844402928e+168\n",
      "[-1.24633725e+80 -2.76039435e+74]\n",
      "Loss: 5.177847361609122e+171\n",
      "[1.29976786e+82 1.33736704e+76]\n",
      "Loss: 5.631313216266588e+175\n",
      "[-1.23905480e+84 -1.34138584e+78]\n",
      "Loss: 5.11751499811087e+179\n",
      "[6.09564189e+83 1.46506813e+79]\n",
      "Loss: 1.2385598086402614e+179\n",
      "[-7.30542704e+84 -8.44273476e+78]\n",
      "Loss: 1.7789728051013567e+181\n",
      "[2.61587184e+86 4.55199589e+80]\n",
      "Loss: 2.2809250752997684e+184\n",
      "[ 1.96778286e+85 -2.16312206e+81]\n",
      "Loss: 1.2907211870282619e+182\n",
      "[-5.90511292e+86 -3.29794171e+81]\n",
      "Loss: 1.1623435431504299e+185\n",
      "[2.43072075e+87 1.04655863e+82]\n",
      "Loss: 1.9694648296435222e+186\n",
      "[-1.17830403e+89 -1.64830164e+83]\n",
      "Loss: 4.627994332248184e+189\n",
      "[6.11961170e+88 1.31682176e+84]\n",
      "Loss: 1.248319705933913e+189\n",
      "[-4.79190674e+90 -4.21474427e+84]\n",
      "Loss: 7.654111929487653e+192\n",
      "[-2.05902493e+90  3.23328353e+85]\n",
      "Loss: 1.413192433305792e+192\n",
      "[1.39414380e+92 2.03839033e+86]\n",
      "Loss: 6.478780021749839e+195\n",
      "[ 1.06638080e+92 -4.72030636e+86]\n",
      "Loss: 3.790554345901288e+195\n",
      "[-4.0254769e+92 -2.7901783e+87]\n",
      "Loss: 5.4014799983735615e+196\n",
      "[2.68420179e+94 2.99901289e+88]\n",
      "Loss: 2.4016428222868966e+200\n",
      "[-7.97126638e+95 -1.43469722e+90]\n",
      "Loss: 2.1180330786373337e+203\n",
      "[3.88855691e+97 5.36795456e+91]\n",
      "Loss: 5.040284060328514e+206\n",
      "[-2.11309219e+99 -2.76684782e+93]\n",
      "Loss: 1.488383972825584e+210\n",
      "[5.72653081e+100 1.05902801e+095]\n",
      "Loss: 1.0931035302247032e+213\n",
      "[-4.86977605e+101 -1.59819527e+096]\n",
      "Loss: 7.904894389480227e+214\n",
      "[5.19295473e+102 1.43751568e+097]\n",
      "Loss: 8.988912779781009e+216\n",
      "[-3.52595827e+103 -1.24130573e+098]\n",
      "Loss: 4.144121022657988e+218\n",
      "[9.37775546e+104 1.63706680e+099]\n",
      "Loss: 2.9314055202519e+221\n",
      "[-4.05273858e+106 -5.73577577e+100]\n",
      "Loss: 5.474888447126945e+224\n",
      "[9.42324069e+106 6.38298733e+101]\n",
      "Loss: 2.9599110628368397e+225\n",
      "[-1.69957112e+108 -3.21245332e+102]\n",
      "Loss: 9.628458895693233e+227\n",
      "[-2.29720367e+107  1.15168385e+103]\n",
      "Loss: 1.7590455927431932e+226\n",
      "[1.57234580e+109 2.92675813e+103]\n",
      "Loss: 8.240891990702727e+229\n",
      "[-1.29280381e+109 -1.66553053e+104]\n",
      "Loss: 5.571130602265827e+229\n",
      "[4.05513740e+110 5.08615485e+104]\n",
      "Loss: 5.481371542181838e+232\n",
      "[-2.01671051e+112 -2.58725233e+106]\n",
      "Loss: 1.355705056875824e+236\n",
      "[8.22056002e+113 1.15852889e+108]\n",
      "Loss: 2.252583525077655e+239\n",
      "[-9.34003899e+114 -2.49765301e+109]\n",
      "Loss: 2.907873250393733e+241\n",
      "[-4.24151954e+114  3.71096784e+109]\n",
      "Loss: 5.9968203544590355e+240\n",
      "[8.92585729e+115 2.15381667e+110]\n",
      "Loss: 2.6556936299999524e+243\n",
      "[-4.10200943e+117 -5.23254979e+111]\n",
      "Loss: 5.608818706602103e+246\n",
      "[2.85004798e+119 2.99963587e+113]\n",
      "Loss: 2.7075870989017462e+250\n",
      "[-6.48890876e+120 -1.19522640e+115]\n",
      "Loss: 1.4035291265279616e+253\n",
      "[3.22234195e+121 1.27106134e+116]\n",
      "Loss: 3.461157366573204e+254\n",
      "[-7.20189689e+122 -1.23220329e+117]\n",
      "Loss: 1.7289080343530674e+257\n",
      "[4.31209015e+124 4.75752405e+118]\n",
      "Loss: 6.198031182676514e+260\n",
      "[-2.32527340e+125 -8.94663729e+119]\n",
      "Loss: 1.8022960939083455e+262\n",
      "[1.45926907e+126 4.49880533e+120]\n",
      "Loss: 7.098210039042895e+263\n",
      "[-6.63775126e+127 -8.06297050e+121]\n",
      "Loss: 1.468655856729711e+267\n",
      "[2.05339511e+129 3.11272714e+123]\n",
      "Loss: 1.4054750556543633e+270\n",
      "[-8.18094153e+130 -1.08042756e+125]\n",
      "Loss: 2.230923464178679e+273\n",
      "[1.05057484e+132 2.45718586e+126]\n",
      "Loss: 3.679019488052162e+275\n",
      "[-4.49494511e+132 -1.77837110e+127]\n",
      "Loss: 6.734833756375019e+276\n",
      "[1.12746291e+134 1.73758769e+128]\n",
      "Loss: 4.237235716443061e+279\n",
      "[-1.18228789e+135 -2.99852523e+129]\n",
      "Loss: 4.659341897011617e+281\n",
      "[6.09916205e+136 6.78227292e+130]\n",
      "Loss: 1.2399907314709102e+285\n",
      "[-2.23371360e+138 -3.00695725e+132]\n",
      "Loss: 1.6631563245375552e+288\n",
      "[5.30913486e+139 8.79022359e+133]\n",
      "Loss: 9.395623575570448e+290\n",
      "[-2.55906483e+141 -2.94223396e+135]\n",
      "Loss: 2.1829343277261075e+294\n",
      "[1.68160171e+142 5.40650980e+136]\n",
      "Loss: 9.425933547363024e+295\n",
      "[-6.26517983e+142 -2.40406289e+137]\n",
      "Loss: 1.3084139819811992e+297\n",
      "[5.06504718e+143 1.27310658e+138]\n",
      "Loss: 8.5515548189131e+298\n",
      "[-7.92391883e+144 -1.52061469e+139]\n",
      "Loss: 2.0929465151310284e+301\n",
      "[1.59351268e+146 2.73678498e+140]\n",
      "Loss: inf\n",
      "[-4.88972745e+146 -2.26396202e+141]\n",
      "Loss: inf\n",
      "[2.16216125e+148 2.35655575e+142]\n",
      "Loss: inf\n",
      "[-1.17467348e+150 -1.23349060e+144]\n",
      "Loss: inf\n",
      "[1.02358671e+151 2.72386925e+145]\n",
      "Loss: inf\n",
      "[-8.80708122e+151 -2.18221181e+146]\n",
      "Loss: inf\n",
      "[2.14876478e+153 3.19903316e+147]\n",
      "Loss: inf\n",
      "[-4.68282044e+152 -1.49670816e+148]\n",
      "Loss: inf\n",
      "[2.08315077e+154 9.10540071e+147]\n",
      "Loss: inf\n",
      "[ 1.47846052e+154 -7.60130862e+148]\n",
      "Loss: inf\n",
      "[-2.46441452e+155 -5.44964419e+149]\n",
      "Loss: inf\n",
      "[1.99855291e+156 5.03969593e+150]\n",
      "Loss: inf\n",
      "[-9.88022462e+157 -1.00992967e+152]\n",
      "Loss: inf\n",
      "[-6.73365749e+157  3.13454379e+152]\n",
      "Loss: inf\n",
      "[8.55367114e+158 2.15694821e+153]\n",
      "Loss: inf\n",
      "[-4.14069341e+158 -5.51109240e+153]\n",
      "Loss: inf\n",
      "[-3.86924957e+158 -4.73485105e+153]\n",
      "Loss: inf\n",
      "[-3.81442105e+158 -4.39930318e+153]\n",
      "Loss: inf\n",
      "[4.97940014e+159 5.96610162e+153]\n",
      "Loss: inf\n",
      "[-1.06941829e+161 -1.64295920e+155]\n",
      "Loss: inf\n",
      "[7.97175666e+161 2.06710122e+156]\n",
      "Loss: inf\n",
      "[ 4.80800014e+161 -1.51870464e+156]\n",
      "Loss: inf\n",
      "[-9.94519305e+161 -7.50214654e+156]\n",
      "Loss: inf\n",
      "[4.08769547e+163 3.81130088e+157]\n",
      "Loss: inf\n",
      "[-3.97552046e+164 -9.03451166e+158]\n",
      "Loss: inf\n",
      "[1.32597696e+165 4.88930054e+159]\n",
      "Loss: inf\n",
      "[-9.89218800e+165 -2.19656969e+160]\n",
      "Loss: inf\n",
      "[-1.66003467e+165  4.05539793e+160]\n",
      "Loss: inf\n",
      "[3.1743081e+166 9.1885423e+160]\n",
      "Loss: inf\n",
      "[-5.78611655e+167 -8.62809707e+161]\n",
      "Loss: inf\n",
      "[4.43026027e+167 4.38416108e+162]\n",
      "Loss: inf\n",
      "[-4.54177731e+168 -5.70657480e+162]\n",
      "Loss: inf\n",
      "[1.82445636e+170 1.91182177e+164]\n",
      "Loss: inf\n",
      "[-1.83118364e+171 -3.88333259e+165]\n",
      "Loss: inf\n",
      "[3.35598714e+172 4.99622029e+166]\n",
      "Loss: inf\n",
      "[-8.04114123e+173 -1.06587864e+168]\n",
      "Loss: inf\n",
      "[-7.37718193e+173  4.64157759e+167]\n",
      "Loss: inf\n",
      "[1.26161878e+175 2.11436176e+169]\n",
      "Loss: inf\n",
      "[-2.21207685e+176 -3.34910392e+170]\n",
      "Loss: inf\n",
      "[-1.77150544e+176  3.09011580e+170]\n",
      "Loss: inf\n",
      "[6.11325399e+177 7.15999808e+171]\n",
      "Loss: inf\n",
      "[-8.06107893e+178 -1.41524659e+173]\n",
      "Loss: inf\n",
      "[2.46996251e+178 4.50459413e+173]\n",
      "Loss: inf\n",
      "[-3.82676022e+179 -1.90806395e+173]\n",
      "Loss: inf\n",
      "[8.90261943e+180 1.17993944e+175]\n",
      "Loss: inf\n",
      "[-6.42331576e+181 -1.49693869e+176]\n",
      "Loss: inf\n",
      "[2.18065797e+183 2.24155865e+177]\n",
      "Loss: inf\n",
      "[-1.62983003e+184 -3.75323506e+178]\n",
      "Loss: inf\n",
      "[9.31646097e+184 2.25790174e+179]\n",
      "Loss: inf\n",
      "[-5.59242993e+185 -1.30348608e+180]\n",
      "Loss: inf\n",
      "[8.26810630e+186 1.24095615e+181]\n",
      "Loss: inf\n",
      "[-1.56140691e+188 -2.14003617e+182]\n",
      "Loss: inf\n",
      "[2.13252007e+187 8.03109473e+182]\n",
      "Loss: inf\n",
      "[-5.56084342e+187  5.56859589e+182]\n",
      "Loss: inf\n",
      "[3.75701220e+188 1.49367465e+183]\n",
      "Loss: inf\n",
      "[-5.24437922e+189 -7.25211659e+183]\n",
      "Loss: inf\n",
      "[8.51065678e+189 4.36108920e+184]\n",
      "Loss: inf\n",
      "[-5.61870760e+189 -2.17299286e+184]\n",
      "Loss: inf\n",
      "[1.42127387e+191 1.49088826e+185]\n",
      "Loss: inf\n",
      "[-3.52915512e+192 -4.11204051e+186]\n",
      "Loss: inf\n",
      "[3.79460087e+193 6.68986857e+187]\n",
      "Loss: inf\n",
      "[-1.23514536e+195 -1.21668728e+189]\n",
      "Loss: inf\n",
      "[7.60564752e+194 7.90630871e+189]\n",
      "Loss: inf\n",
      "[4.83743717e+194 5.25344488e+189]\n",
      "Loss: inf\n",
      "[-5.13992096e+195 -4.23472149e+189]\n",
      "Loss: inf\n",
      "[5.95400701e+196 1.00128075e+191]\n",
      "Loss: inf\n",
      "[-1.70430324e+198 -1.74546002e+192]\n",
      "Loss: inf\n",
      "[2.16253104e+199 3.39855189e+193]\n",
      "Loss: inf\n",
      "[-3.55085916e+200 -4.74900783e+194]\n",
      "Loss: inf\n",
      "[-1.38686739e+200  1.08016021e+195]\n",
      "Loss: inf\n",
      "[1.99288729e+201 4.11501682e+195]\n",
      "Loss: inf\n",
      "[-2.73588544e+202 -3.83612561e+196]\n",
      "Loss: inf\n",
      "[5.37548552e+203 6.48617459e+197]\n",
      "Loss: inf\n",
      "[-4.38243734e+204 -8.29295842e+198]\n",
      "Loss: inf\n",
      "[4.51523129e+204 2.58685358e+199]\n",
      "Loss: inf\n",
      "[-1.67838453e+204 -2.91675471e+198]\n",
      "Loss: inf\n",
      "[2.03862527e+205 3.00419558e+199]\n",
      "Loss: inf\n",
      "[-9.64668484e+205 -2.32974246e+200]\n",
      "Loss: inf\n",
      "[3.75314919e+206 9.10880552e+200]\n",
      "Loss: inf\n",
      "[3.69827539e+206 6.68772463e+200]\n",
      "Loss: inf\n",
      "[-9.08840507e+207 -9.25898344e+201]\n",
      "Loss: inf\n",
      "[-6.74044375e+207  1.51389687e+202]\n",
      "Loss: inf\n",
      "[-6.68554731e+207  1.83356401e+202]\n",
      "Loss: inf\n",
      "[4.50048582e+206 5.44502451e+202]\n",
      "Loss: inf\n",
      "[-4.38955491e+207  4.67721861e+202]\n",
      "Loss: inf\n",
      "[9.55740608e+208 1.55206236e+203]\n",
      "Loss: inf\n",
      "[-4.74802127e+209 -1.04734272e+204]\n",
      "Loss: inf\n",
      "[-3.36020434e+209  2.68160962e+203]\n",
      "Loss: inf\n",
      "[1.54290656e+210 4.31974682e+204]\n",
      "Loss: inf\n",
      "[-1.98507894e+211 -2.48288443e+205]\n",
      "Loss: inf\n",
      "[-8.40227012e+210  5.12713900e+205]\n",
      "Loss: inf\n",
      "[5.62873166e+211 1.68371027e+206]\n",
      "Loss: inf\n",
      "[-1.32530500e+212 -3.46839106e+206]\n",
      "Loss: inf\n",
      "[-1.03698070e+212 -3.94604022e+205]\n",
      "Loss: inf\n",
      "[2.34442512e+213 2.45338189e+207]\n",
      "Loss: inf\n",
      "[-8.64181714e+213 -2.25301135e+208]\n",
      "Loss: inf\n",
      "[4.83756406e+213 3.03345585e+208]\n",
      "Loss: inf\n",
      "[-8.33345288e+214 -7.03179410e+208]\n",
      "Loss: inf\n",
      "[1.70319850e+215 6.34694687e+209]\n",
      "Loss: inf\n",
      "[-3.21582289e+216 -3.02939489e+210]\n",
      "Loss: inf\n",
      "[4.35974072e+217 5.58724343e+211]\n",
      "Loss: inf\n",
      "[-8.24881509e+218 -8.73577466e+212]\n",
      "Loss: inf\n",
      "[6.35220387e+219 1.06902992e+214]\n",
      "Loss: inf\n",
      "[ 1.39802298e+218 -1.90156328e+214]\n",
      "Loss: inf\n",
      "[-1.79375869e+219 -2.14619057e+214]\n",
      "Loss: inf\n",
      "[-1.17174286e+219 -1.65168734e+214]\n",
      "Loss: inf\n",
      "[2.06124010e+220 7.01683708e+213]\n",
      "Loss: inf\n",
      "[-1.70328601e+221 -2.83743718e+215]\n",
      "Loss: inf\n",
      "[2.51695929e+222 2.83615204e+216]\n",
      "Loss: inf\n",
      "[-2.28795879e+223 -3.38483160e+217]\n",
      "Loss: inf\n",
      "[4.44589981e+224 4.38296430e+218]\n",
      "Loss: inf\n",
      "[-3.38883221e+225 -5.49184634e+219]\n",
      "Loss: inf\n",
      "[2.5056918e+225 1.4708508e+220]\n",
      "Loss: inf\n",
      "[-3.17056835e+226 -2.69281894e+220]\n",
      "Loss: inf\n",
      "[3.35642156e+227 4.55966116e+221]\n",
      "Loss: inf\n",
      "[-2.51298801e+228 -3.89733454e+222]\n",
      "Loss: inf\n",
      "[4.95155521e+227 8.28202525e+222]\n",
      "Loss: inf\n",
      "[-8.29537934e+228 -9.13489273e+221]\n",
      "Loss: inf\n",
      "[3.38225121e+229 8.10587133e+223]\n",
      "Loss: inf\n",
      "[3.36546104e+229 7.06603919e+223]\n",
      "Loss: inf\n",
      "[-1.44299018e+230 -2.65329391e+224]\n",
      "Loss: inf\n",
      "[1.36950609e+229 3.86929570e+224]\n",
      "Loss: inf\n",
      "[-1.90695223e+229  2.95881684e+224]\n",
      "Loss: inf\n",
      "[-1.87391323e+229  3.06616300e+224]\n",
      "Loss: inf\n",
      "[6.04628906e+228 3.98321433e+224]\n",
      "Loss: inf\n",
      "[-4.45108918e+229  3.24297147e+224]\n",
      "Loss: inf\n",
      "[-2.68797928e+229  4.42309858e+224]\n",
      "Loss: inf\n",
      "[-2.34731552e+229  4.82419563e+224]\n",
      "Loss: inf\n",
      "[3.12294637e+230 8.52670694e+224]\n",
      "Loss: inf\n",
      "[3.08441793e+230 7.08730627e+224]\n",
      "Loss: inf\n",
      "[-3.83259532e+230 -1.19836403e+225]\n",
      "Loss: inf\n",
      "[1.64344650e+231 2.42227973e+225]\n",
      "Loss: inf\n",
      "[-8.42850140e+231 -1.42078659e+226]\n",
      "Loss: inf\n",
      "[3.63579701e+232 6.48104435e+226]\n",
      "Loss: inf\n",
      "[-1.83074387e+233 -2.96638428e+227]\n",
      "Loss: inf\n",
      "[3.39096815e+232 5.05856027e+227]\n",
      "Loss: inf\n",
      "[3.38001888e+232 4.98136579e+227]\n",
      "Loss: inf\n",
      "[-2.06032896e+233  1.39244703e+227]\n",
      "Loss: inf\n",
      "[2.14791401e+234 2.90130865e+228]\n",
      "Loss: inf\n",
      "[-1.02213387e+235 -1.74393442e+229]\n",
      "Loss: inf\n",
      "[6.86329499e+235 9.40334424e+229]\n",
      "Loss: inf\n",
      "[-8.44275392e+236 -8.83878674e+230]\n",
      "Loss: inf\n",
      "[1.04211063e+238 1.11042812e+232]\n",
      "Loss: inf\n",
      "[ 7.95103269e+237 -8.51878922e+231]\n",
      "Loss: inf\n",
      "[-7.50177950e+236 -4.05279516e+232]\n",
      "Loss: inf\n",
      "[ 1.17200672e+237 -3.59299406e+232]\n",
      "Loss: inf\n",
      "[-1.00116013e+238 -4.97231050e+232]\n",
      "Loss: inf\n",
      "[-6.80257113e+236 -1.30836195e+232]\n",
      "Loss: inf\n",
      "[ 2.44667203e+236 -1.00918183e+232]\n",
      "Loss: inf\n",
      "[-1.35271067e+237 -1.24379500e+232]\n",
      "Loss: inf\n",
      "[1.52032877e+238 5.23294012e+231]\n",
      "Loss: inf\n",
      "[-5.82267941e+238 -1.18904173e+233]\n",
      "Loss: inf\n",
      "[9.15301577e+238 2.26293939e+233]\n",
      "Loss: inf\n",
      "[-6.89074723e+239 -7.56876496e+233]\n",
      "Loss: inf\n",
      "[3.96039940e+240 5.79376374e+234]\n",
      "Loss: inf\n",
      "[-6.96902565e+240 -1.81633458e+235]\n",
      "Loss: inf\n",
      "[4.36083914e+241 4.98584699e+235]\n",
      "Loss: inf\n",
      "[-2.75465674e+242 -3.75379709e+236]\n",
      "Loss: inf\n",
      "[-2.71103788e+242 -2.51045695e+236]\n",
      "Loss: inf\n",
      "[8.78739892e+242 1.74157140e+237]\n",
      "Loss: inf\n",
      "[ 3.51950264e+242 -6.74462557e+236]\n",
      "Loss: inf\n",
      "[ 3.09415446e+242 -1.10676211e+237]\n",
      "Loss: inf\n",
      "[ 1.78771493e+242 -1.81357604e+237]\n",
      "Loss: inf\n",
      "[-1.49642381e+243 -3.72778306e+237]\n",
      "Loss: inf\n",
      "[3.93083273e+242 2.12451195e+237]\n",
      "Loss: inf\n",
      "[-4.19859733e+243 -2.52781641e+237]\n",
      "Loss: inf\n",
      "[1.88959049e+244 3.14008082e+238]\n",
      "Loss: inf\n",
      "[-2.97965246e+244 -7.25892943e+238]\n",
      "Loss: inf\n",
      "[2.57132201e+245 2.42813004e+239]\n",
      "Loss: inf\n",
      "[-9.36737174e+245 -1.63766938e+240]\n",
      "Loss: inf\n",
      "[3.39124979e+246 5.16191046e+240]\n",
      "Loss: inf\n",
      "[ 2.62671578e+245 -5.78272306e+240]\n",
      "Loss: inf\n",
      "[-6.59933898e+245 -7.42853413e+240]\n",
      "Loss: inf\n",
      "[ 1.80959272e+246 -3.18194646e+240]\n",
      "Loss: inf\n",
      "[ 5.97010806e+245 -8.08477359e+240]\n",
      "Loss: inf\n",
      "[-5.43453944e+246 -1.43339644e+241]\n",
      "Loss: inf\n",
      "[-4.58408631e+246 -7.28959091e+240]\n",
      "Loss: inf\n",
      "[3.76916150e+247 3.80967544e+241]\n",
      "Loss: inf\n",
      "[-1.61024755e+248 -2.42647064e+242]\n",
      "Loss: inf\n",
      "[4.63485097e+247 3.47161821e+242]\n",
      "Loss: inf\n",
      "[-1.31943739e+248  5.52240287e+241]\n",
      "Loss: inf\n",
      "[1.40379764e+248 6.60928463e+242]\n",
      "Loss: inf\n",
      "[-1.54072939e+248  1.45283536e+241]\n",
      "Loss: inf\n",
      "[-1.50166159e+248  9.21408552e+241]\n",
      "Loss: inf\n",
      "[9.06621428e+248 1.34602230e+243]\n",
      "Loss: inf\n",
      "[-1.53132177e+249 -3.31004199e+243]\n",
      "Loss: inf\n",
      "[-4.32155199e+247  1.39390029e+243]\n",
      "Loss: inf\n",
      "[1.16850733e+248 1.65176930e+243]\n",
      "Loss: inf\n",
      "[-2.81736704e+248  9.85998866e+242]\n",
      "Loss: inf\n",
      "[1.90608668e+249 3.39586224e+243]\n",
      "Loss: inf\n",
      "[-1.09010256e+250 -1.16937856e+244]\n",
      "Loss: inf\n",
      "[9.94610170e+249 3.41158208e+244]\n",
      "Loss: inf\n",
      "[-6.96638554e+250 -5.09641851e+244]\n",
      "Loss: inf\n",
      "[-3.87077445e+250  8.87408039e+244]\n",
      "Loss: inf\n",
      "[1.63739769e+251 3.53717524e+245]\n",
      "Loss: inf\n",
      "[ 7.67022151e+250 -1.83239634e+243]\n",
      "Loss: inf\n",
      "[-2.87128207e+251 -4.96873450e+245]\n",
      "Loss: inf\n",
      "[-1.08243350e+251  1.71362865e+245]\n",
      "Loss: inf\n",
      "[-5.73874291e+250  3.89030735e+245]\n",
      "Loss: inf\n",
      "[-7.01546719e+249  5.45974247e+245]\n",
      "Loss: inf\n",
      "[3.72246648e+250 5.97141801e+245]\n",
      "Loss: inf\n",
      "[1.34450407e+250 5.11162554e+245]\n",
      "Loss: inf\n",
      "[-1.09325935e+250  4.59106628e+245]\n",
      "Loss: inf\n",
      "[3.52730824e+250 5.23407995e+245]\n",
      "Loss: inf\n",
      "[-3.58058512e+250  3.80873266e+245]\n",
      "Loss: inf\n",
      "[1.25849025e+251 5.96358512e+245]\n",
      "Loss: inf\n",
      "[-7.43406881e+251 -3.35741438e+245]\n",
      "Loss: inf\n",
      "[3.92035378e+252 4.88536737e+246]\n",
      "Loss: inf\n",
      "[ 2.24270370e+252 -2.26967561e+246]\n",
      "Loss: inf\n",
      "[-1.12288641e+253 -1.75281651e+247]\n",
      "Loss: inf\n",
      "[1.25255505e+253 2.75819773e+247]\n",
      "Loss: inf\n",
      "[-6.87499141e+253 -6.01039417e+247]\n",
      "Loss: inf\n",
      "[4.10098131e+254 4.36036071e+248]\n",
      "Loss: inf\n",
      "[-7.83494865e+254 -1.46749047e+249]\n",
      "Loss: inf\n",
      "[8.50014103e+253 7.65601272e+248]\n",
      "Loss: inf\n",
      "[-4.06365059e+254  2.15125853e+248]\n",
      "Loss: inf\n",
      "[4.99022287e+254 1.84073110e+249]\n",
      "Loss: inf\n",
      "[-2.74984031e+255 -1.55460635e+249]\n",
      "Loss: inf\n",
      "[1.14506066e+255 7.12853450e+249]\n",
      "Loss: inf\n",
      "[-2.02973378e+255  2.09509851e+249]\n",
      "Loss: inf\n",
      "[2.70660051e+255 1.02393431e+250]\n",
      "Loss: inf\n",
      "[-2.32004468e+255  5.99301976e+248]\n",
      "Loss: inf\n",
      "[1.49976342e+255 8.34060798e+249]\n",
      "Loss: inf\n",
      "[-3.77433587e+254  3.99921409e+249]\n",
      "Loss: inf\n",
      "[1.63341608e+255 6.24201414e+249]\n",
      "Loss: inf\n",
      "[1.60958575e+255 5.73664173e+249]\n",
      "Loss: inf\n",
      "[1.60727479e+255 5.58119957e+249]\n",
      "Loss: inf\n",
      "[-5.36745532e+255 -2.90947203e+249]\n",
      "Loss: inf\n",
      "[9.46499693e+255 1.96039530e+250]\n",
      "Loss: inf\n",
      "[-3.39222390e+256 -3.12716652e+250]\n",
      "Loss: inf\n",
      "[1.64752583e+257 1.73797204e+251]\n",
      "Loss: inf\n",
      "[ 4.42451175e+256 -1.76411354e+251]\n",
      "Loss: inf\n",
      "[-1.14309115e+257 -3.83541284e+251]\n",
      "Loss: inf\n",
      "[-1.02077339e+257 -2.91533610e+251]\n",
      "Loss: inf\n",
      "[2.7130466e+257 1.8643328e+251]\n",
      "Loss: inf\n",
      "[ 1.86285721e+256 -4.51367067e+251]\n",
      "Loss: inf\n",
      "[ 7.50670517e+255 -4.86254601e+251]\n",
      "Loss: inf\n",
      "[ 4.38309393e+255 -4.97932439e+251]\n",
      "Loss: inf\n",
      "[ 1.54187339e+255 -5.06400221e+251]\n",
      "Loss: inf\n",
      "[ 1.43023431e+255 -5.07390772e+251]\n",
      "Loss: inf\n",
      "[ 1.36484990e+255 -5.08117217e+251]\n",
      "Loss: inf\n",
      "[-2.69691666e+255 -5.13682402e+251]\n",
      "Loss: inf\n",
      "[ 2.46450836e+255 -5.04908035e+251]\n",
      "Loss: inf\n",
      "[-1.86134779e+255 -5.12548433e+251]\n",
      "Loss: inf\n",
      "[ 6.21496776e+255 -5.03521238e+251]\n",
      "Loss: inf\n",
      "[-3.37299044e+255 -5.21403915e+251]\n",
      "Loss: inf\n",
      "[-3.34201071e+255 -5.20658816e+251]\n",
      "Loss: inf\n",
      "[ 3.62928092e+255 -5.09588863e+251]\n",
      "Loss: inf\n",
      "[-1.10482373e+255 -5.19047576e+251]\n",
      "Loss: inf\n",
      "[ 2.61295419e+255 -5.14445979e+251]\n",
      "Loss: inf\n",
      "[-4.40976509e+255 -5.24123331e+251]\n",
      "Loss: inf\n",
      "[-9.53104508e+254 -5.15347430e+251]\n",
      "Loss: inf\n",
      "[ 5.44940797e+254 -5.12675003e+251]\n",
      "Loss: inf\n",
      "[ 3.02931655e+254 -5.13483133e+251]\n",
      "Loss: inf\n",
      "[-9.50556506e+254 -5.14847530e+251]\n",
      "Loss: inf\n",
      "[ 3.15869073e+255 -5.10493453e+251]\n",
      "Loss: inf\n",
      "[-1.58664004e+255 -5.18979988e+251]\n",
      "Loss: inf\n",
      "[-1.58658258e+255 -5.18959165e+251]\n",
      "Loss: inf\n",
      "[ 4.79094484e+255 -5.12056190e+251]\n",
      "Loss: inf\n",
      "[ 2.16809324e+255 -5.19710284e+251]\n",
      "Loss: inf\n",
      "[-3.22620166e+255 -5.27057458e+251]\n",
      "Loss: inf\n",
      "[ 5.87894702e+255 -5.15471796e+251]\n",
      "Loss: inf\n",
      "[-7.15343390e+255 -5.34088845e+251]\n",
      "Loss: inf\n",
      "[ 7.91628466e+255 -5.12116488e+251]\n",
      "Loss: inf\n",
      "[ 2.49492271e+255 -5.25910776e+251]\n",
      "Loss: inf\n",
      "[ 2.31962927e+255 -5.27296298e+251]\n",
      "Loss: inf\n",
      "[ 1.07462037e+255 -5.30838840e+251]\n",
      "Loss: inf\n",
      "[-4.94631750e+254 -5.33532304e+251]\n",
      "Loss: inf\n",
      "[ 5.62162489e+254 -5.32040228e+251]\n",
      "Loss: inf\n",
      "[ 5.56933584e+254 -5.32151557e+251]\n",
      "Loss: inf\n",
      "[ 5.38515630e+254 -5.32358481e+251]\n",
      "Loss: inf\n",
      "[-8.16396196e+254 -5.34094931e+251]\n",
      "Loss: inf\n",
      "[ 1.03456229e+255 -5.31608514e+251]\n",
      "Loss: inf\n",
      "[-3.02336103e+255 -5.35732080e+251]\n",
      "Loss: inf\n",
      "[-1.83255247e+255 -5.31932582e+251]\n",
      "Loss: inf\n",
      "[-1.28420581e+255 -5.29935325e+251]\n",
      "Loss: inf\n",
      "[ 6.37826723e+254 -5.26820790e+251]\n",
      "Loss: inf\n",
      "[-9.23671467e+254 -5.28789290e+251]\n",
      "Loss: inf\n",
      "[ 1.28088987e+254 -5.26854882e+251]\n",
      "Loss: inf\n",
      "[ 1.27344916e+253 -5.27092250e+251]\n",
      "Loss: inf\n",
      "[ 8.41935329e+250 -5.27116911e+251]\n",
      "Loss: inf\n",
      "[-2.21860206e+251 -5.27117221e+251]\n",
      "Loss: inf\n",
      "[ 2.43670102e+251 -5.27116603e+251]\n",
      "Loss: inf\n",
      "[-6.08444374e+250 -5.27117124e+251]\n",
      "Loss: inf\n",
      "[ 5.55694973e+249 -5.27117003e+251]\n",
      "Loss: inf\n",
      "[-1.03942303e+250 -5.27117021e+251]\n",
      "Loss: inf\n",
      "[-8.75657476e+249 -5.27117013e+251]\n",
      "Loss: inf\n",
      "[ 7.36835093e+248 -5.27116996e+251]\n",
      "Loss: inf\n",
      "[-1.80247929e+248 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-1.50268153e+248 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 2.11041636e+248 -5.27116997e+251]\n",
      "Loss: inf\n",
      "[ 1.51038026e+248 -5.27116997e+251]\n",
      "Loss: inf\n",
      "[ 1.17682925e+248 -5.27116997e+251]\n",
      "Loss: inf\n",
      "[ 2.69504237e+247 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-3.35609179e+247 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.31648145e+247 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.17628857e+247 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-2.06195229e+247 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-4.70303186e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 4.26373228e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 3.75175810e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-5.59341188e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-5.53398467e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.41395203e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.40270268e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 4.65725508e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 2.37397539e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 2.13528928e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 2.20138610e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.67316757e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-1.36708434e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.30198492e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 3.51246953e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.40725403e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.05147310e+244 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 3.75712976e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.57333668e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.04420482e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.23979221e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.75825052e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.12012186e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.18229459e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.74816539e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17814771e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 4.89390724e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09988311e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.01236947e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.30532969e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11467576e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.47149049e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.02598681e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.17724876e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[-1.70611921e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.91969360e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.34438879e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.64479800e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.81929236e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.32966618e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.08185804e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.62267014e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.05289692e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.70958127e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.15491393e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.83397049e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.52273737e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.10766440e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.03137353e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 3.55544776e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.76703719e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 3.94678087e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.01790534e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.57914731e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.36982220e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.06193348e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.39962807e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.54143077e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.64996619e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.17251216e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.80516540e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.36476855e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.89650894e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.98119489e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.17005243e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.60617200e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.72236879e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.03022537e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.47758441e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.71565213e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.03279914e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.13476902e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.15119118e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.24245912e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.31452969e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 3.55409339e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 4.67879529e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.43529468e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.89407959e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21282339e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.33611849e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.80877264e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.09674835e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.01381608e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.10564522e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.27774549e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.02434537e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.04871183e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.67850349e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.74082222e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.05881877e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.07628477e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.28767687e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.92162097e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.46026694e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.13038213e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.50255584e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.95032772e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.27322844e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.15448188e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.41557761e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.18470417e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.34710010e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.45646026e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 5.89413101e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.18294522e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.93100655e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.03975193e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.02381847e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.92578906e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.78093050e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09082724e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.87136209e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.38537657e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.14908926e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.18461688e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.60324601e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.98142164e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.35509287e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.43640624e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15528766e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.59690274e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24124612e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25844474e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.48348655e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.24906526e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.06935033e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.93209465e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.07726963e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.52818968e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.00548773e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.28741757e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.65326339e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.32371723e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.92803371e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.14674978e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.50455359e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.00357001e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.03758345e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.08427296e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 1.11133220e+246 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.82580123e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.68568706e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.35931478e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.49292699e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.58875700e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.63025748e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.21243605e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.55014983e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.83875451e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.45780117e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.02630365e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.40115569e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.84743686e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.04372790e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.85807382e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.40906890e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.56262657e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.99636754e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.44671060e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.91416120e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.51815538e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.83092587e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.36428118e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.95979821e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.02275901e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.56740928e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10579787e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.30307842e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.66869727e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.11897743e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14764093e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09569795e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.34952828e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.21560597e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.64534238e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.83813139e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.37166314e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.55142162e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.09670585e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.57615955e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.51078817e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.02183042e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.36012439e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.69557957e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.15779664e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.60777949e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.62239379e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.45379020e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.55412966e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.94052221e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.30626718e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.71663329e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.48828890e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.91128790e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.13926644e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.42142279e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.23172915e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.02436836e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.41807231e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.42111234e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.68633220e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.91780882e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.26299953e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.60819801e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.88641985e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21490404e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.49015644e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.54838435e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.81500649e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.90359080e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.03913108e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.30462248e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.99585773e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 9.01302059e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.71745081e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.30960211e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.41716991e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.46261919e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.67785992e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.43979716e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25372549e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.96225998e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.05569670e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.75434308e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.84780966e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.39564642e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.89291654e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.18794187e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.34154133e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.94913415e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 6.97359722e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.27836887e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.47810015e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.10940600e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.25601550e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.29727017e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.38575856e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.62376397e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.88156052e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.59781138e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.85180753e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.88117997e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.98988204e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.08559373e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.30878422e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.31272525e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.47892715e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.51448778e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.71889790e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.41561507e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.39318349e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14382657e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.86457862e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.29449331e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.40408391e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.18085005e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.36420911e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.58491650e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.63054149e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.42441344e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.50037331e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.15022184e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.26089914e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.46146042e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.62146261e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.81935549e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.00460926e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.02463617e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.60645586e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.79700081e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.39037909e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.56470770e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.68519149e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.79749632e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.94369004e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.00066619e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10650715e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25554435e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.02516114e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16954029e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16682426e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.32350669e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.42851622e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.48380750e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.58466982e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.59534938e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.69907514e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17237592e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.31738273e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10184917e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.95660989e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.84585700e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.98102106e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11402848e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.82130990e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.92083995e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.89755033e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.63577728e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.28158861e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.41135562e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.42202621e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.52264360e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.40187582e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.44256753e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.50375674e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.28089571e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.40948644e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.52568085e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.65576655e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.37118351e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.49821366e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.19687007e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.18602562e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.01593554e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.07269544e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.15305237e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.26878877e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.28815795e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.28254616e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.24696791e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.04420658e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.07731845e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.12155048e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.19648777e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.25544859e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.35400861e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.36301925e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.46848540e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.48108668e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.55701888e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.65508551e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.73127524e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.80741295e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.89261522e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.96966474e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.00293482e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.08003704e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.08164078e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16381800e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22144324e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.30741484e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.01891469e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.03720190e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.06679051e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.93716470e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.02231843e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.04985505e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13063796e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18604654e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25008095e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25269244e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.29787604e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.36933184e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22028574e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.06493120e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11572687e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14117335e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.04582536e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11879270e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17767581e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24866893e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.08136510e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13844676e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11308039e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.92533154e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.88801907e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.90579932e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.96710805e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.01161477e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.02071760e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.06384654e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.07241254e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10605499e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.94151780e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.94681879e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.00379728e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.06202515e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10510494e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.96519092e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.97765088e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 7.99988316e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.05041798e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10152279e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11043565e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14135269e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19686416e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25105147e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.28090101e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.33387073e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.38487456e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.43304911e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.35284026e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.40240326e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.41531362e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.30278264e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.34664074e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22674291e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23756937e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22176289e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26290284e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.29024186e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.33203305e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.37610832e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23213638e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.27003592e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26262150e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.28960298e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.33011161e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26966070e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23237689e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.27497810e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14361662e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16512114e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20678201e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24257424e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26752616e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.29545920e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.29527748e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.31092919e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.34863610e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.37459704e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.37584159e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.28057538e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.31359608e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.34923725e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23225405e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23281138e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25717655e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.29182685e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.32490700e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.28716950e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23841771e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26916628e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22894866e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23075029e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26394022e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.29649570e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.32566267e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21837228e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25034420e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25833793e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26723649e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21165391e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24236618e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18211585e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13445559e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15996580e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.06542345e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09152894e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10434226e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11242409e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13115528e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15464901e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15860005e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.07886790e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.06468187e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.06240939e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.07878364e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.08657986e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.10812274e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.12364672e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13718931e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16265607e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.12523725e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09945680e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.12069424e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13565193e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15262619e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17636427e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19173588e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21315333e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22184300e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23121029e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20446004e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22454717e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21262724e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23394317e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23434528e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25306039e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.27388677e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.29438990e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.31471945e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.31414129e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.33270883e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.32799848e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.34777321e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.35761085e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.37556546e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.36307088e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.32182153e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.34016264e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.35116420e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.36934343e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.37809767e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.33496297e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.28955013e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22570207e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20927698e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22602971e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24348260e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22217948e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19141364e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20843689e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19027382e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16505699e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17886074e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19463368e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18524129e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19052225e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20456969e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17631881e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17703696e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15903533e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16915361e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16918850e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18416597e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14779576e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13385677e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14846000e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16288125e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16366152e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17705930e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18812905e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19036284e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20226544e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21548417e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21299356e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20690907e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.21765214e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22606171e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.23815769e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25070184e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25361628e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24161430e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25331914e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26544571e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26148468e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25741919e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25416879e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24631031e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24948950e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25969667e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.24579495e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25661105e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25428516e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25101656e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26036761e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26815539e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26982979e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.27841944e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25064029e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.25917256e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26780955e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.26219142e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.22985927e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.20215262e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17540849e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18156305e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18644272e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19407112e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18754877e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19129831e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17852340e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18482193e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.19329921e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.18868386e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.17341424e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15822541e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.16371570e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14847486e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.15505547e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.13928113e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14727131e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.14435377e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11646677e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11995132e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11748721e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.12530332e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.11066486e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.08486128e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09041381e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09820065e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.08244485e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09005002e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "[ 8.09724716e+245 -5.27116998e+251]\n",
      "Loss: inf\n",
      "Time: 10.207780361175537\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(base_lr=1e-10)\n",
    "\n",
    "data = get_data(1_000_000)\n",
    "\n",
    "start = time.time()\n",
    "model.fit(data[:,0].reshape((-1, 1)), data[:,1])\n",
    "print(\"Time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "f29dca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28df4c80bb0>]"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "\n",
    "x_vals = np.sort(data[:, 0])\n",
    "y_vals = model.predict(x_vals.reshape(-1, 1))\n",
    "\n",
    "plt.plot(x_vals, y_vals, color='red')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
