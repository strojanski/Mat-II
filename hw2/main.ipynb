{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d7dbea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "8caae505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    x,y,z = x\n",
    "    return (x - z)**2 + (2*y + z)**2 + (4*x - 2*y + z)**2 + x + y\n",
    "\n",
    "def grad_f1(x):\n",
    "    x,y,z = x\n",
    "    dx = 2*(x - z) + 8*(4*x - 2*y + z) + 1\n",
    "    dy = 4*(2*y + z) - 4*(4*x - 2*y + z) + 1\n",
    "    dz = -2*(x - z) + 2*(2*y + z) + 2*(4*x - 2*y + z)\n",
    "    \n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def hess_f1(x):\n",
    "    dxx = 34 # 2 + 32\n",
    "    dxy = -16\n",
    "    dxz = 6 #-2 + 8\n",
    "    dyy = 0\n",
    "    dyz = 8\n",
    "    dzz = 6\n",
    "    \n",
    "    return np.array([[dxx, dxy, dxz], [dxy, dyy, dyz], [dxz, dyz, dzz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "08eaaa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0),\n",
       " array([1, 1, 0]),\n",
       " array([[ 34, -16,   6],\n",
       "        [-16,   0,   8],\n",
       "        [  6,   8,   6]]))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_x1 = np.array([0,0,0]) \n",
    "f1(f1_x1), grad_f1(f1_x1), hess_f1(f1_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c45d29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    x,y,z = x\n",
    "    return (x - 1)**2 + (y - 1)**2 + 100*(y-x**2)**2 + 100*(z-y**2)**2\n",
    "\n",
    "def grad_f2(x):\n",
    "    x,y,z = x\n",
    "    dx = 2*x - 2 - 400 * x * y + 400 * x**3\n",
    "    dy = 2*y - 2 + 200 * (y - x**2) - 400*z*y + 400 * y**3\n",
    "    dz = 200 * (z - y**2)\n",
    "        \n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def hess_f2(x):\n",
    "    x,y,z = x\n",
    "    \n",
    "    dxx = 2 - 400 * y + 1200 * x**2\n",
    "    dxy = -400 * x\n",
    "    dxz = 0\n",
    "    dyy = 2 + 200 - 400 * z + 1200 * y**2\n",
    "    dyz = -400 * y\n",
    "    dzz = 200\n",
    "    return np.array([[dxx, dxy, dxz], [dxy, dyy, dyz], [dxz, dyz, dzz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "6fff7db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(11.6),\n",
       " array([115.6,  67.6, -48. ]),\n",
       " array([[1250., -480.,    0.],\n",
       "        [-480., 1450., -480.],\n",
       "        [   0., -480.,  200.]]))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2_x1 = np.array([1.2, 1.2, 1.2])\n",
    "f2(f2_x1), grad_f2(f2_x1), hess_f2(f2_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b2ac8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    x,y = x\n",
    "    return (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "\n",
    "def grad_f3(x):\n",
    "    x,y = x\n",
    "    \n",
    "    dx = -12.75 * 6*x + 3*y - 4*x*y - 2*x*y**2 + 4.5*y**2 + 2*x*y**4 - 4*x*y**3 + 5.25 * y**3 + 2*x*y**6\n",
    "    dy = 3*x + 9*y*x - 4*x**2*y - 2*x**2 + 15.75*y**2 *x + 2*x**2 * y - 6 * x**2 * y**2 + 4*x**3*y**3 + 6*x**2*y**5\n",
    "    \n",
    "    return np.array([dx, dy])\n",
    "\n",
    "def hess_f3(x):\n",
    "    x,y = x\n",
    "    \n",
    "    dxx = 6 - 4*y - 2*y**2 + 2*y**4 - 4*y**3 + 2*y**6\n",
    "    dxy = 3 - 4*x - 4*x*y + 9*y + 8*x*y**3 - 12*x*y**2 + 15.75*y**2 + 12*x*y**5\n",
    "    dyy = 9*x - 4*x**2 + 31.5*y*x + 2*x**2 - 12*x**2*y + 12*x**2*y**2 + 30*x**2*y**4\n",
    "    return np.array([[dxx, dxy], [dxy, dyy]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "b6582d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(14.203125),\n",
       " array([-69.75,  27.75]),\n",
       " array([[ 0.  , 27.75],\n",
       "        [27.75, 68.5 ]]))"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3_x1 = np.array([1,1])\n",
    "f3(f3_x1), grad_f3(f3_x1), hess_f3(f3_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "bdd8fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(i):\n",
    "    return 0.01 * 0.99**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8f3a8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(x, grad_f, lr_fn, n_steps, t=None):\n",
    "    \n",
    "    if t is not None:\n",
    "        i = 0\n",
    "        start = time.time()\n",
    "        while time.time() - start < t:\n",
    "            x = x - lr_fn(i) * grad_f(x)\n",
    "            i += 1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            x = x - lr_fn(i) * grad_f(x)\n",
    "        \n",
    "    return x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "06be5673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyak(x: np.ndarray, grad_f, lr_fn, mu, n_steps, t=None):\n",
    "    x_prev = x\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        while time.time() - start < t:\n",
    "            dx = grad_f(x)\n",
    "            x = x - lr_fn(i) * dx  + mu * (x - x_prev)\n",
    "        \n",
    "            x_prev = x\n",
    "            i+=1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            dx = grad_f(x)\n",
    "            x = x - lr_fn(i) * dx  + mu * (x - x_prev)\n",
    "            \n",
    "            x_prev = x\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "42bb25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(x, f, grad_f, lr_fn, mu, n_steps, t=None):\n",
    "    x_prev = x\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        while time.time() - start < t:\n",
    "            dx = grad_f(x + mu * (x - x_prev))\n",
    "            x = x - lr_fn(i) * dx + mu * (x_prev - x)\n",
    "        \n",
    "            x_prev = x\n",
    "            i+=1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            dx = grad_f(x + mu * (x - x_prev))\n",
    "            x = x - lr_fn(i) * dx + mu * (x_prev - x)\n",
    "            \n",
    "            x_prev = x\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "044fa1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad(x, grad_f, lr_fn, n_steps, eps=1e-8, t=None):\n",
    "    x = np.array(x, dtype=float)\n",
    "    n = len(x)\n",
    "    \n",
    "    grad_sq_sum = np.zeros(n)\n",
    "    \n",
    "     \n",
    "    if t is not None:\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        while time.time() - start < t:\n",
    "            grad = np.array(grad_f(x))\n",
    "        \n",
    "            # Accumulate squared gradients\n",
    "            grad_sq_sum += grad ** 2\n",
    "            \n",
    "            # Compute D_k^{-1/2}\n",
    "            D_inv_sqrt = np.diag(1.0 / (np.sqrt(grad_sq_sum) + eps))\n",
    "            \n",
    "            # Adaptive step\n",
    "            step = lr_fn(i) * D_inv_sqrt @ grad\n",
    "            x_new = x - step\n",
    "            \n",
    "            x = x_new\n",
    "            i+= 1\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            grad = np.array(grad_f(x))\n",
    "            \n",
    "            # Accumulate squared gradients\n",
    "            grad_sq_sum += grad ** 2\n",
    "            \n",
    "            # Compute D_k^{-1/2}\n",
    "            D_inv_sqrt = np.diag(1.0 / (np.sqrt(grad_sq_sum) + eps))\n",
    "            \n",
    "            # Adaptive step\n",
    "            step = lr_fn(i) * D_inv_sqrt @ grad\n",
    "            x_new = x - step\n",
    "            \n",
    "            x = x_new\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "93b767ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.15969334544827538)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(adagrad(f1_x1, grad_f1, learning_rate, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94603437",
   "metadata": {},
   "source": [
    "Newton and BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e15c33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_positive_definite(H):\n",
    "    try:\n",
    "        np.linalg.cholesky(H)\n",
    "        return True\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "bb4858f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(x0, grad_f, hess_f, n_steps=100, t=None):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    \n",
    "    if t is not None:\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        while time.time() - start < t:\n",
    "            grad = np.array(grad_f(x))\n",
    "            hess = np.array(hess_f(x))\n",
    "            \n",
    "            hess_inv = np.linalg.inv(hess)\n",
    "            \n",
    "            # Compute Newton step\n",
    "            x = x - learning_rate(i) * hess_inv @ grad\n",
    "            i += 1\n",
    "\n",
    "    else:\n",
    "        for i in range(n_steps):\n",
    "            grad = np.array(grad_f(x))\n",
    "            grad = np.clip(grad, -10, 10)\n",
    "\n",
    "            hess = np.array(hess_f(x)) + 1e-4 * np.eye(len(x))\n",
    "            \n",
    "            hess_inv = np.linalg.inv(hess)\n",
    "            \n",
    "            \n",
    "            # Compute Newton step\n",
    "            x = x - learning_rate(i) * np.linalg.solve(hess, grad)\n",
    "\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e96eed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton:  0.07391146130764983\n"
     ]
    }
   ],
   "source": [
    "print(\"Newton: \", f1(newton(np.array([0,0,0]), grad_f1, hess_f1, 100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb9f53",
   "metadata": {},
   "source": [
    "## TODO: BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063c60a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2eb0fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum2(f):\n",
    "    \"\"\"Finds approximate minimum of f(x)\"\"\"\n",
    "    xs = np.linspace(-1, 1, 1000)\n",
    "    ys = np.linspace(-1, 1, 1000)\n",
    "    X, Y = np.meshgrid(xs, ys)  \n",
    "    Z = f(np.array([X, Y]))  \n",
    "    \n",
    "    min_idx = np.unravel_index(np.argmin(Z), Z.shape)  \n",
    "    bx, by, bz = X[min_idx], Y[min_idx], Z[min_idx]\n",
    "    return np.array([bx, by, bz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "bf59e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum3(f):\n",
    "    \"\"\"Finds approximate minimum of f(x)\"\"\"\n",
    "    xs = np.linspace(-1, 1, 100)\n",
    "    ys = np.linspace(-1, 1, 100)\n",
    "    zs = np.linspace(-1, 1, 100)\n",
    "    \n",
    "    X, Y, Z = np.meshgrid(xs, ys, zs)  \n",
    "    W = f(np.array([X, Y, Z]))  \n",
    "    \n",
    "    min_idx = np.unravel_index(np.argmin(W), W.shape)  \n",
    "    bx, by, bz, bw = X[min_idx], Y[min_idx], Z[min_idx], W[min_idx]\n",
    "    return np.array([bx, by, bz, bw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8be12379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 minimum: [-0.17171717 -0.23232323  0.17171717 -0.19773493]\n",
      "f2 minimum: [1. 1. 1. 0.]\n",
      "f3 minimum: [ 1.         -0.18718719  4.36852892]\n"
     ]
    }
   ],
   "source": [
    "f1_xopt = minimum3(f1)\n",
    "f2_xopt = minimum3(f2)\n",
    "f3_xopt = minimum2(f3)\n",
    "print(\"f1 minimum:\", f1_xopt)\n",
    "print(\"f2 minimum:\", f2_xopt)\n",
    "print(\"f3 minimum:\", f3_xopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f9009436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum -0.19773492500765227\n",
      "Steps,  2\n",
      "GD:  -0.035101752536\n",
      "Polyak:  -0.035101752536\n",
      "Nesterov:  -0.035101752536\n",
      "Adagrad:  -0.03156182988530955\n",
      "Newton:  0.0015077275337369443\n",
      "\n",
      "Steps,  5\n",
      "GD:  -0.07159791032768308\n",
      "Polyak:  -0.07159791032768308\n",
      "Nesterov:  -0.07159791032768308\n",
      "Adagrad:  -0.055560190582874064\n",
      "Newton:  0.00381477728519076\n",
      "\n",
      "Steps,  10\n",
      "GD:  -0.10989895086006889\n",
      "Polyak:  -0.10989895086006889\n",
      "Nesterov:  -0.10989895086006889\n",
      "Adagrad:  -0.07927804062158532\n",
      "Newton:  0.0077552790699727935\n",
      "\n",
      "Steps,  100\n",
      "GD:  -0.1945330755830976\n",
      "Polyak:  -0.1945330755830976\n",
      "Nesterov:  -0.1945330755830976\n",
      "Adagrad:  -0.15969334544827538\n",
      "Newton:  0.07391146130764983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### f1:\n",
    "f1x0 = np.array([0, 0, 0])\n",
    "f1x1 = np.array([1, 1, 0])\n",
    "\n",
    "steps = [2, 5, 10, 100]\n",
    "f = f1\n",
    "grad_f = grad_f1\n",
    "hess_f = hess_f1\n",
    "\n",
    "print(\"True minimum\", f1_xopt[-1])\n",
    "for step in steps:\n",
    "    print(\"Steps, \", step)\n",
    "    print(\"GD: \", f(gd(f1x0, grad_f, learning_rate, step)))\n",
    "    print(\"Polyak: \", f(polyak(f1x0, grad_f, learning_rate, 0.9, step)))\n",
    "    print(\"Nesterov: \", f(nesterov(f1x0, f, grad_f, learning_rate, 0.9, step)))\n",
    "    print(\"Adagrad: \", f(adagrad(f1x0, grad_f, learning_rate, step)))\n",
    "    print(\"Newton: \", f(newton(f1x0, grad_f, hess_f, step)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6b4c5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time(f, grad_f, hess_f, x0, step, times):\n",
    "    print(\"True minimum\", f1_xopt[-1])\n",
    "    for _time in times:\n",
    "        print(\"Time, \", _time)\n",
    "        print(\"GD: \", f(gd(x0, grad_f, learning_rate, step, t=_time)))\n",
    "        print(\"Polyak: \", f(polyak(x0, grad_f, learning_rate, 0.9, step, t=_time)))\n",
    "        print(\"Nesterov: \", f(nesterov(x0, f, grad_f, learning_rate, 0.9, step, t=_time)))\n",
    "        print(\"Adagrad: \", f(adagrad(x0, grad_f, learning_rate, 0.9, step, t=_time)))\n",
    "        print(\"Newton: \", f(newton(x0, grad_f, hess_f, step, t=_time)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75761e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7546db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True minimum -0.19773492500765227\n",
      "Time,  0.1\n",
      "GD:  -0.1975114672774948\n",
      "Polyak:  -0.1975114672774948\n",
      "Nesterov:  -0.1975114672774948\n",
      "Adagrad:  -0.0019650811794469543\n",
      "Newton:  0.140621296199624\n",
      "\n",
      "Time,  1\n",
      "GD:  -0.1975114672774948\n",
      "Polyak:  -0.1975114672774948\n",
      "Nesterov:  -0.1975114672774948\n",
      "Adagrad:  -0.0019650811794469543\n",
      "Newton:  0.140621296199624\n",
      "\n",
      "Time,  2\n",
      "GD:  -0.1975114672774948\n",
      "Polyak:  -0.1975114672774948\n",
      "Nesterov:  -0.1975114672774948\n",
      "Adagrad:  -0.0019650811794469543\n",
      "Newton:  0.140621296199624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "f1x0 = np.array([0, 0, 0])\n",
    "f1x1 = np.array([1, 1, 0])\n",
    "f2x0 = np.array([1.2, 1.2, 1.2])\n",
    "f2x1 = np.array([-1, 1.2, 1.2])\n",
    "f2x0 = np.array([1,1])\n",
    "f2x1 = np.array([4.5, 4.5])\n",
    "\n",
    "times = [.1, 1, 2]\n",
    "f = f1\n",
    "grad_f = grad_f1\n",
    "hess_f = hess_f1\n",
    "step = 1000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
